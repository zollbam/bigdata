{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto MPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로딩\n",
    "from urllib.request import urlopen,urlretrieve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./orgin_autompg.csv', <http.client.HTTPMessage at 0x1e64a963be0>)"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data','./autompg.csv')\n",
    "urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.names','./desci_autompg.txt')\n",
    "urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original','./orgin_autompg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- autompg.csv는 우리가 분석할때 사용할 데이터\n",
    "- desci_autompg.txt는 우리가 분석할 데이터의 설명\n",
    "- orgin_autompg.csv는 원본 데이터 인듯 => 행수가 점더 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 데이터 를 데프 형태로 만들기\n",
    "# re(정규표현식) => \\s:화이트 스페이스\n",
    "autompg_df=pd.read_csv('./autompg.csv',header=None,sep='\\s+')\n",
    "print(type(autompg_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데프인 것을 확인\n",
    "- 1. mpg(연비):           continuous  \n",
    "  2. cylinders(실린더):     multi-valued discrete  \n",
    "  3. displacement(이동):  continuous  \n",
    "  4. horsepower(마력):    continuous  \n",
    "  5. weight(무게):        continuous  \n",
    "  6. acceleration(가속도):  continuous  \n",
    "  7. model year(모델년도):    multi-valued discrete  \n",
    "  8. origin(출신, 근원):        multi-valued discrete  \n",
    "  9. car name(차 이름):      string (unique for each instance)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 열이름 변경\n",
    "autompg_df.columns=['MPG','Cyl','Dis','HP','Weight','Acc','Model_year','Origin','Car_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MPG         398 non-null    float64\n",
      " 1   Cyl         398 non-null    int64  \n",
      " 2   Dis         398 non-null    float64\n",
      " 3   HP          398 non-null    object \n",
      " 4   Weight      398 non-null    float64\n",
      " 5   Acc         398 non-null    float64\n",
      " 6   Model_year  398 non-null    int64  \n",
      " 7   Origin      398 non-null    int64  \n",
      " 8   Car_name    398 non-null    object \n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# 정보 확인하기\n",
    "autompg_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HP열은 연속형인데 object로 되어 있어서 변경이 필요해 보임\n",
    "- 웹사이트에서는 결측치가 있다고 했는데 결측치는 없음???? 왜 없는지 찾아보자\n",
    "- Car_name의 중복된 데이터가 있는지 확인 해보자\n",
    "- Model_year년도에서 가장 많은 년도 비중을 차지하는 곳을 찾아보자\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 열의 고유값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18. , 15. , 16. , 17. , 14. , 24. , 22. , 21. , 27. , 26. , 25. ,\n",
       "       10. , 11. ,  9. , 28. , 19. , 12. , 13. , 23. , 30. , 31. , 35. ,\n",
       "       20. , 29. , 32. , 33. , 17.5, 15.5, 14.5, 22.5, 24.5, 18.5, 29.5,\n",
       "       26.5, 16.5, 31.5, 36. , 25.5, 33.5, 20.5, 30.5, 21.5, 43.1, 36.1,\n",
       "       32.8, 39.4, 19.9, 19.4, 20.2, 19.2, 25.1, 20.6, 20.8, 18.6, 18.1,\n",
       "       17.7, 27.5, 27.2, 30.9, 21.1, 23.2, 23.8, 23.9, 20.3, 21.6, 16.2,\n",
       "       19.8, 22.3, 17.6, 18.2, 16.9, 31.9, 34.1, 35.7, 27.4, 25.4, 34.2,\n",
       "       34.5, 31.8, 37.3, 28.4, 28.8, 26.8, 41.5, 38.1, 32.1, 37.2, 26.4,\n",
       "       24.3, 19.1, 34.3, 29.8, 31.3, 37. , 32.2, 46.6, 27.9, 40.8, 44.3,\n",
       "       43.4, 36.4, 44.6, 40.9, 33.8, 32.7, 23.7, 23.6, 32.4, 26.6, 25.8,\n",
       "       23.5, 39.1, 39. , 35.1, 32.3, 37.7, 34.7, 34.4, 29.9, 33.7, 32.9,\n",
       "       31.6, 28.1, 30.7, 24.2, 22.4, 34. , 38. , 44. ])"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mpg의 고유값\n",
    "autompg_df.MPG.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모두 실수이므로 넘어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    204\n",
       "8    103\n",
       "6     84\n",
       "3      4\n",
       "5      3\n",
       "Name: Cyl, dtype: int64"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autompg_df.Cyl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cyl 고유값은 [8 4 6 3 5], 고유값의 개수는 5\n",
      "Cyl 고유값의 빈도표\n",
      "4    204\n",
      "8    103\n",
      "6     84\n",
      "3      4\n",
      "5      3\n",
      "Name: Cyl, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cyl의 고유값\n",
    "print(f\"Cyl 고유값은 {autompg_df.Cyl.unique()}, 고유값의 개수는 {autompg_df.Cyl.nunique()}\")\n",
    "print(f\"Cyl 고유값의 빈도표\\n{autompg_df.Cyl.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cyl에는 총 5개의 범주가 있다.\n",
    "- 3과 5의 실린더값의 개수 너무 작음  \n",
    "  이상값인지 확인 해보자\n",
    "- 실린더는 3/4/5/6/8/12/16기통이 있으므로 이상치같은 것은 아닌 것으로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dis 고유값은 [307.  350.  318.  304.  302.  429.  454.  440.  455.  390.  383.  340.\n",
      " 400.  113.  198.  199.  200.   97.  110.  107.  104.  121.  360.  140.\n",
      "  98.  232.  225.  250.  351.  258.  122.  116.   79.   88.   71.   72.\n",
      "  91.   97.5  70.  120.   96.  108.  155.   68.  114.  156.   76.   83.\n",
      "  90.  231.  262.  134.  119.  171.  115.  101.  305.   85.  130.  168.\n",
      " 111.  260.  151.  146.   80.   78.  105.  131.  163.   89.  267.   86.\n",
      " 183.  141.  173.  135.   81.  100.  145.  112.  181.  144. ], 고유값의 개수는 82\n",
      "Dis 고유값의 빈도표\n",
      "97.0     21\n",
      "98.0     18\n",
      "350.0    18\n",
      "318.0    17\n",
      "250.0    17\n",
      "         ..\n",
      "104.0     1\n",
      "110.0     1\n",
      "130.0     1\n",
      "111.0     1\n",
      "144.0     1\n",
      "Name: Dis, Length: 82, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dis의 고유값\n",
    "print(f\"Dis 고유값은 {autompg_df.Dis.unique()}, 고유값의 개수는 {autompg_df.Dis.nunique()}\")\n",
    "print(f\"Dis 고유값의 빈도표\\n{autompg_df.Dis.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 고유값이 다 수치형이라 패쓰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP 고유값은 ['130.0' '165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0'\n",
      " '170.0' '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00'\n",
      " '113.0' '200.0' '210.0' '193.0' '?' '100.0' '105.0' '175.0' '153.0'\n",
      " '180.0' '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00'\n",
      " '80.00' '54.00' '208.0' '155.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00']\n",
      "HP 고유값의 빈도표\n",
      "150.0    22\n",
      "90.00    20\n",
      "88.00    19\n",
      "110.0    18\n",
      "100.0    17\n",
      "         ..\n",
      "61.00     1\n",
      "93.00     1\n",
      "148.0     1\n",
      "152.0     1\n",
      "82.00     1\n",
      "Name: HP, Length: 94, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# HP의 고유값\n",
    "print(f\"HP 고유값은 {autompg_df.HP.unique()}\")\n",
    "print(f\"HP 고유값의 빈도표\\n{autompg_df.HP.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 물음표(?)가 하나 고유값에 포함되어 있다.  \n",
    "  이것을 어떻게 처리할지 고민 해봐야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 고유값은 [3504. 3693. 3436. 3433. 3449. 4341. 4354. 4312. 4425. 3850. 3563. 3609.\n",
      " 3761. 3086. 2372. 2833. 2774. 2587. 2130. 1835. 2672. 2430. 2375. 2234.\n",
      " 2648. 4615. 4376. 4382. 4732. 2264. 2228. 2046. 2634. 3439. 3329. 3302.\n",
      " 3288. 4209. 4464. 4154. 4096. 4955. 4746. 5140. 2962. 2408. 3282. 3139.\n",
      " 2220. 2123. 2074. 2065. 1773. 1613. 1834. 1955. 2278. 2126. 2254. 2226.\n",
      " 4274. 4385. 4135. 4129. 3672. 4633. 4502. 4456. 4422. 2330. 3892. 4098.\n",
      " 4294. 4077. 2933. 2511. 2979. 2189. 2395. 2288. 2506. 2164. 2100. 4100.\n",
      " 3988. 4042. 3777. 4952. 4363. 4237. 4735. 4951. 3821. 3121. 3278. 2945.\n",
      " 3021. 2904. 1950. 4997. 4906. 4654. 4499. 2789. 2279. 2401. 2379. 2124.\n",
      " 2310. 2472. 2265. 4082. 4278. 1867. 2158. 2582. 2868. 3399. 2660. 2807.\n",
      " 3664. 3102. 2875. 2901. 3336. 2451. 1836. 2542. 3781. 3632. 3613. 4141.\n",
      " 4699. 4457. 4638. 4257. 2219. 1963. 2300. 1649. 2003. 2125. 2108. 2246.\n",
      " 2489. 2391. 2000. 3264. 3459. 3432. 3158. 4668. 4440. 4498. 4657. 3907.\n",
      " 3897. 3730. 3785. 3039. 3221. 3169. 2171. 2639. 2914. 2592. 2702. 2223.\n",
      " 2545. 2984. 1937. 3211. 2694. 2957. 2671. 1795. 2464. 2572. 2255. 2202.\n",
      " 4215. 4190. 3962. 3233. 3353. 3012. 3085. 2035. 3651. 3574. 3645. 3193.\n",
      " 1825. 1990. 2155. 2565. 3150. 3940. 3270. 2930. 3820. 4380. 4055. 3870.\n",
      " 3755. 2045. 1945. 3880. 4060. 4140. 4295. 3520. 3425. 3630. 3525. 4220.\n",
      " 4165. 4325. 4335. 1940. 2740. 2755. 2051. 2075. 1985. 2190. 2815. 2600.\n",
      " 2720. 1800. 2070. 3365. 3735. 3570. 3535. 3155. 2965. 3430. 3210. 3380.\n",
      " 3070. 3620. 3410. 3445. 3205. 4080. 2560. 2230. 2515. 2745. 2855. 2405.\n",
      " 2830. 3140. 2795. 2135. 3245. 2990. 2890. 3265. 3360. 3840. 3725. 3955.\n",
      " 3830. 4360. 4054. 3605. 1925. 1975. 1915. 2670. 3530. 3900. 3190. 3420.\n",
      " 2200. 2150. 2020. 2595. 2700. 2556. 2144. 1968. 2120. 2019. 2678. 2870.\n",
      " 3003. 3381. 2188. 2711. 2434. 2110. 2800. 2085. 2335. 2950. 3250. 1850.\n",
      " 2145. 1845. 2910. 2420. 2500. 2905. 2290. 2490. 2635. 2620. 2725. 2385.\n",
      " 1755. 1875. 1760. 2050. 2215. 2380. 2320. 2210. 2350. 2615. 3230. 3160.\n",
      " 2900. 3415. 3060. 3465. 2605. 2640. 2575. 2525. 2735. 2865. 3035. 1980.\n",
      " 2025. 1970. 2160. 2205. 2245. 1965. 1995. 3015. 2585. 2835. 2665. 2370.\n",
      " 2790. 2295. 2625.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Weight의 고유값\n",
    "print(f\"Weight 고유값은 {autompg_df.Weight.unique()}\")\n",
    "plt.boxplot(autompg_df.Weight)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weight열에는 이상치는 없는 것으로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 고유값은 [12.  11.5 11.  10.5 10.   9.   8.5  8.   9.5 15.  15.5 16.  14.5 20.5\n",
      " 17.5 12.5 14.  13.5 18.5 19.  13.  19.5 18.  17.  23.5 16.5 21.  16.9\n",
      " 14.9 17.7 15.3 13.9 12.8 15.4 17.6 22.2 22.1 14.2 17.4 16.2 17.8 12.2\n",
      " 16.4 13.6 15.7 13.2 21.9 16.7 12.1 14.8 18.6 16.8 13.7 11.1 11.4 18.2\n",
      " 15.8 15.9 14.1 21.5 14.4 19.4 19.2 17.2 18.7 15.1 13.4 11.2 14.7 16.6\n",
      " 17.3 15.2 14.3 20.1 24.8 11.3 12.9 18.8 18.1 17.9 21.7 23.7 19.9 21.8\n",
      " 13.8 12.6 16.1 20.7 18.3 20.4 19.6 17.1 15.6 24.6 11.6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Acc의 고유값\n",
    "print(f\"Weight 고유값은 {autompg_df.Acc.unique()}\")\n",
    "plt.boxplot(autompg_df.Acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 박스플롯으로 이상치들은 보이지만 Acc열 자체가 가속도이므로 심하게 이상치가 아닌 이상\n",
    "  데이터에 포함시키고 분석을 진행할 생각"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_year의 빈도표\n",
      "73    40\n",
      "78    36\n",
      "76    34\n",
      "82    31\n",
      "75    30\n",
      "70    29\n",
      "79    29\n",
      "80    29\n",
      "81    29\n",
      "71    28\n",
      "72    28\n",
      "77    28\n",
      "74    27\n",
      "Name: Model_year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Model_year의 고유값\n",
    "print(f\"Model_year의 빈도표\\n{autompg_df.Model_year.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 년도별 차 개수를 알 수 있음 70~82년 까지 분포해 있는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin 고유값은 [1 3 2]\n",
      "Origin 빈도표\n",
      "1    249\n",
      "3     79\n",
      "2     70\n",
      "Name: Origin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Origin의 고유값\n",
    "print(f\"Origin 고유값은 {autompg_df.Origin.unique()}\")\n",
    "print(f\"Origin 빈도표\\n{autompg_df.Origin.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Origin은 솔직히 아직까지 먼지 모르겠다. 1/2/3으로 범주는 적은데 멀 나타내는 것일까??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car_name  고유값 개수는 305\n",
      "Car_name  빈도표\n",
      "ford pinto             6\n",
      "toyota corolla         5\n",
      "amc matador            5\n",
      "ford maverick          5\n",
      "chevrolet chevette     4\n",
      "                      ..\n",
      "chevrolet monza 2+2    1\n",
      "ford mustang ii        1\n",
      "pontiac astro          1\n",
      "amc pacer              1\n",
      "chevy s-10             1\n",
      "Name: Car_name, Length: 305, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Car_name 의 고유값\n",
    "print(f\"Car_name  고유값 개수는 {autompg_df.Car_name .nunique()}\")\n",
    "print(f\"Car_name  빈도표\\n{autompg_df.Car_name .value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 차이름이 중복되는 것들도 있다.\n",
    "- 차이름이 같으면 데이터도 같은 것이 아닐까??? 확인해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연비를 우리나라에 맞게 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "autompg_df['Mpg_kr']=round(autompg_df.MPG*0.4251437056332947,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight를 파운드에서 KG으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "autompg_df['Weight_KG']=round(autompg_df.Weight*0.453592,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acc는 가속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "autompg_df['Accinter']=pd.qcut(sorted(autompg_df.Acc),3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accinter을 범주형으로\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "autompg_df['Accinter']=le.fit_transform(autompg_df.Accinter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Dis</th>\n",
       "      <th>HP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Model_year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Mpg_kr</th>\n",
       "      <th>Weight_KG</th>\n",
       "      <th>Accinter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>7.6526</td>\n",
       "      <td>1589.3864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>6.3772</td>\n",
       "      <td>1675.1153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>7.6526</td>\n",
       "      <td>1558.5421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>6.8023</td>\n",
       "      <td>1557.1813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>7.2274</td>\n",
       "      <td>1564.4388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "      <td>11.4789</td>\n",
       "      <td>1265.5217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "      <td>18.7063</td>\n",
       "      <td>966.1510</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "      <td>13.6046</td>\n",
       "      <td>1040.9936</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "      <td>11.9040</td>\n",
       "      <td>1190.6790</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "      <td>13.1795</td>\n",
       "      <td>1233.7702</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cyl    Dis     HP  Weight   Acc  Model_year  Origin  \\\n",
       "0    18.0    8  307.0  130.0  3504.0  12.0          70       1   \n",
       "1    15.0    8  350.0  165.0  3693.0  11.5          70       1   \n",
       "2    18.0    8  318.0  150.0  3436.0  11.0          70       1   \n",
       "3    16.0    8  304.0  150.0  3433.0  12.0          70       1   \n",
       "4    17.0    8  302.0  140.0  3449.0  10.5          70       1   \n",
       "..    ...  ...    ...    ...     ...   ...         ...     ...   \n",
       "393  27.0    4  140.0  86.00  2790.0  15.6          82       1   \n",
       "394  44.0    4   97.0  52.00  2130.0  24.6          82       2   \n",
       "395  32.0    4  135.0  84.00  2295.0  11.6          82       1   \n",
       "396  28.0    4  120.0  79.00  2625.0  18.6          82       1   \n",
       "397  31.0    4  119.0  82.00  2720.0  19.4          82       1   \n",
       "\n",
       "                      Car_name   Mpg_kr  Weight_KG  Accinter  \n",
       "0    chevrolet chevelle malibu   7.6526  1589.3864         0  \n",
       "1            buick skylark 320   6.3772  1675.1153         0  \n",
       "2           plymouth satellite   7.6526  1558.5421         0  \n",
       "3                amc rebel sst   6.8023  1557.1813         0  \n",
       "4                  ford torino   7.2274  1564.4388         0  \n",
       "..                         ...      ...        ...       ...  \n",
       "393            ford mustang gl  11.4789  1265.5217         2  \n",
       "394                  vw pickup  18.7063   966.1510         2  \n",
       "395              dodge rampage  13.6046  1040.9936         2  \n",
       "396                ford ranger  11.9040  1190.6790         2  \n",
       "397                 chevy s-10  13.1795  1233.7702         2  \n",
       "\n",
       "[398 rows x 12 columns]"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autompg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HP의 ?를 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Dis</th>\n",
       "      <th>HP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Model_year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Mpg_kr</th>\n",
       "      <th>Weight_KG</th>\n",
       "      <th>Accinter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>ford pinto</td>\n",
       "      <td>10.6286</td>\n",
       "      <td>928.0492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2875.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "      <td>8.9280</td>\n",
       "      <td>1304.0770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>40.9</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>renault lecar deluxe</td>\n",
       "      <td>17.3884</td>\n",
       "      <td>832.3413</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>23.6</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2905.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang cobra</td>\n",
       "      <td>10.0334</td>\n",
       "      <td>1317.6848</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>34.5</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>renault 18i</td>\n",
       "      <td>14.6675</td>\n",
       "      <td>1052.3334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>amc concord dl</td>\n",
       "      <td>9.7783</td>\n",
       "      <td>1376.6517</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cyl    Dis HP  Weight   Acc  Model_year  Origin  \\\n",
       "32   25.0    4   98.0  ?  2046.0  19.0          71       1   \n",
       "126  21.0    6  200.0  ?  2875.0  17.0          74       1   \n",
       "330  40.9    4   85.0  ?  1835.0  17.3          80       2   \n",
       "336  23.6    4  140.0  ?  2905.0  14.3          80       1   \n",
       "354  34.5    4  100.0  ?  2320.0  15.8          81       2   \n",
       "374  23.0    4  151.0  ?  3035.0  20.5          82       1   \n",
       "\n",
       "                 Car_name   Mpg_kr  Weight_KG  Accinter  \n",
       "32             ford pinto  10.6286   928.0492         0  \n",
       "126         ford maverick   8.9280  1304.0770         0  \n",
       "330  renault lecar deluxe  17.3884   832.3413         2  \n",
       "336    ford mustang cobra  10.0334  1317.6848         2  \n",
       "354           renault 18i  14.6675  1052.3334         2  \n",
       "374        amc concord dl   9.7783  1376.6517         2  "
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HP가 ?표인 행을 찾기\n",
    "autompg_df[autompg_df.HP=='?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예전에 인터넷으로 뒤져서 찾아 놓은 정보를 활용하여 값을 변경\n",
    "autompg_df.iloc[32,3]=75\n",
    "autompg_df.iloc[126,3]=140\n",
    "autompg_df.iloc[330,3]=53.3\n",
    "autompg_df.iloc[336,3]=120\n",
    "autompg_df.iloc[354,3]=81.5\n",
    "autompg_df.iloc[374,3]=82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Dis</th>\n",
       "      <th>HP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Model_year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Mpg_kr</th>\n",
       "      <th>Weight_KG</th>\n",
       "      <th>Accinter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MPG, Cyl, Dis, HP, Weight, Acc, Model_year, Origin, Car_name, Mpg_kr, Weight_KG, Accinter]\n",
       "Index: []"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값이 변경 되었는지 확인\n",
    "autompg_df[autompg_df.HP=='?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타입변경\n",
    "autompg_df.HP=autompg_df.HP.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 물음표 값이 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origin은 도대체 멀까??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Dis</th>\n",
       "      <th>HP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Model_year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Mpg_kr</th>\n",
       "      <th>Weight_KG</th>\n",
       "      <th>Accinter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2430.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100 ls</td>\n",
       "      <td>10.2034</td>\n",
       "      <td>1102.2286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>114.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>8.5029</td>\n",
       "      <td>1171.1745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2694.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>9.7783</td>\n",
       "      <td>1221.9768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>34.3</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 4000</td>\n",
       "      <td>14.5824</td>\n",
       "      <td>992.4593</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>20.3</td>\n",
       "      <td>5</td>\n",
       "      <td>131.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 5000</td>\n",
       "      <td>8.6304</td>\n",
       "      <td>1283.6654</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "      <td>18.7063</td>\n",
       "      <td>966.1510</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>vw rabbit</td>\n",
       "      <td>12.3292</td>\n",
       "      <td>878.6077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>41.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>vw rabbit</td>\n",
       "      <td>17.6435</td>\n",
       "      <td>972.5012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>44.3</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>vw rabbit c (diesel)</td>\n",
       "      <td>18.8339</td>\n",
       "      <td>945.7393</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>vw rabbit custom</td>\n",
       "      <td>13.5621</td>\n",
       "      <td>873.1646</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cyl    Dis     HP  Weight   Acc  Model_year  Origin  \\\n",
       "21   24.0    4  107.0   90.0  2430.0  14.5          70       2   \n",
       "119  20.0    4  114.0   91.0  2582.0  14.0          73       2   \n",
       "177  23.0    4  115.0   95.0  2694.0  15.0          75       2   \n",
       "317  34.3    4   97.0   78.0  2188.0  15.8          80       2   \n",
       "274  20.3    5  131.0  103.0  2830.0  15.9          78       2   \n",
       "..    ...  ...    ...    ...     ...   ...         ...     ...   \n",
       "394  44.0    4   97.0   52.0  2130.0  24.6          82       2   \n",
       "197  29.0    4   90.0   70.0  1937.0  14.2          76       2   \n",
       "309  41.5    4   98.0   76.0  2144.0  14.7          80       2   \n",
       "325  44.3    4   90.0   48.0  2085.0  21.7          80       2   \n",
       "293  31.9    4   89.0   71.0  1925.0  14.0          79       2   \n",
       "\n",
       "                 Car_name   Mpg_kr  Weight_KG  Accinter  \n",
       "21            audi 100 ls  10.2034  1102.2286         0  \n",
       "119            audi 100ls   8.5029  1171.1745         0  \n",
       "177            audi 100ls   9.7783  1221.9768         1  \n",
       "317             audi 4000  14.5824   992.4593         2  \n",
       "274             audi 5000   8.6304  1283.6654         2  \n",
       "..                    ...      ...        ...       ...  \n",
       "394             vw pickup  18.7063   966.1510         2  \n",
       "197             vw rabbit  12.3292   878.6077         1  \n",
       "309             vw rabbit  17.6435   972.5012         2  \n",
       "325  vw rabbit c (diesel)  18.8339   945.7393         2  \n",
       "293      vw rabbit custom  13.5621   873.1646         2  \n",
       "\n",
       "[149 rows x 12 columns]"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autompg_df[((autompg_df.Origin==3) | (autompg_df.Origin==2))].sort_values(['Car_name','Model_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- origin은 나라를 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'origin'열을 나라 이름으로 바꾸어 새로운 열 만들기\n",
    "country=[]\n",
    "for i in autompg_df.Origin:\n",
    "    if i==1:\n",
    "        country.append('USA')\n",
    "    elif i==2:\n",
    "        country.append('EU')\n",
    "    elif i==3:\n",
    "        country.append('JAPAN')\n",
    "\n",
    "country_Sr=pd.Series(country,name='country')\n",
    "autompg_df=pd.concat([autompg_df,country_Sr],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_year의 중복되는 차들 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ford pinto            6\n",
       "toyota corolla        5\n",
       "amc matador           5\n",
       "ford maverick         5\n",
       "chevrolet chevette    4\n",
       "Name: Car_name, dtype: int64"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autompg_df.Car_name .value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Dis</th>\n",
       "      <th>HP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Model_year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Mpg_kr</th>\n",
       "      <th>Weight_KG</th>\n",
       "      <th>Accinter</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>ford pinto</td>\n",
       "      <td>10.6286</td>\n",
       "      <td>928.0492</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>ford pinto</td>\n",
       "      <td>8.0777</td>\n",
       "      <td>1047.7975</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2451.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>ford pinto</td>\n",
       "      <td>11.0537</td>\n",
       "      <td>1111.7540</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2639.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>ford pinto</td>\n",
       "      <td>9.7783</td>\n",
       "      <td>1197.0293</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>171.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2984.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>ford pinto</td>\n",
       "      <td>7.6526</td>\n",
       "      <td>1353.5185</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>26.5</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>ford pinto</td>\n",
       "      <td>11.2663</td>\n",
       "      <td>1163.4635</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cyl    Dis    HP  Weight   Acc  Model_year  Origin    Car_name  \\\n",
       "32   25.0    4   98.0  75.0  2046.0  19.0          71       1  ford pinto   \n",
       "112  19.0    4  122.0  85.0  2310.0  18.5          73       1  ford pinto   \n",
       "130  26.0    4  122.0  80.0  2451.0  16.5          74       1  ford pinto   \n",
       "168  23.0    4  140.0  83.0  2639.0  17.0          75       1  ford pinto   \n",
       "174  18.0    6  171.0  97.0  2984.0  14.5          75       1  ford pinto   \n",
       "206  26.5    4  140.0  72.0  2565.0  13.6          76       1  ford pinto   \n",
       "\n",
       "      Mpg_kr  Weight_KG  Accinter country  \n",
       "32   10.6286   928.0492         0     USA  \n",
       "112   8.0777  1047.7975         0     USA  \n",
       "130  11.0537  1111.7540         0     USA  \n",
       "168   9.7783  1197.0293         1     USA  \n",
       "174   7.6526  1353.5185         1     USA  \n",
       "206  11.2663  1163.4635         1     USA  "
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ford pinto\n",
    "autompg_df[autompg_df.Car_name=='ford pinto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Dis</th>\n",
       "      <th>HP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Model_year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Mpg_kr</th>\n",
       "      <th>Weight_KG</th>\n",
       "      <th>Accinter</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corolla</td>\n",
       "      <td>12.3292</td>\n",
       "      <td>984.7482</td>\n",
       "      <td>1</td>\n",
       "      <td>JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corolla</td>\n",
       "      <td>11.9040</td>\n",
       "      <td>977.4908</td>\n",
       "      <td>1</td>\n",
       "      <td>JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>32.2</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corolla</td>\n",
       "      <td>13.6896</td>\n",
       "      <td>1027.3859</td>\n",
       "      <td>2</td>\n",
       "      <td>JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>32.4</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corolla</td>\n",
       "      <td>13.7747</td>\n",
       "      <td>1065.9412</td>\n",
       "      <td>2</td>\n",
       "      <td>JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>34.0</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2245.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corolla</td>\n",
       "      <td>14.4549</td>\n",
       "      <td>1018.3140</td>\n",
       "      <td>2</td>\n",
       "      <td>JAPAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cyl    Dis    HP  Weight   Acc  Model_year  Origin        Car_name  \\\n",
       "167  29.0    4   97.0  75.0  2171.0  16.0          75       3  toyota corolla   \n",
       "205  28.0    4   97.0  75.0  2155.0  16.4          76       3  toyota corolla   \n",
       "321  32.2    4  108.0  75.0  2265.0  15.2          80       3  toyota corolla   \n",
       "356  32.4    4  108.0  75.0  2350.0  16.8          81       3  toyota corolla   \n",
       "382  34.0    4  108.0  70.0  2245.0  16.9          82       3  toyota corolla   \n",
       "\n",
       "      Mpg_kr  Weight_KG  Accinter country  \n",
       "167  12.3292   984.7482         1   JAPAN  \n",
       "205  11.9040   977.4908         1   JAPAN  \n",
       "321  13.6896  1027.3859         2   JAPAN  \n",
       "356  13.7747  1065.9412         2   JAPAN  \n",
       "382  14.4549  1018.3140         2   JAPAN  "
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toyota corolla\n",
    "autompg_df[autompg_df.Car_name=='toyota corolla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Dis</th>\n",
       "      <th>HP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Model_year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Mpg_kr</th>\n",
       "      <th>Weight_KG</th>\n",
       "      <th>Accinter</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>amc matador</td>\n",
       "      <td>7.6526</td>\n",
       "      <td>1491.4105</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3672.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>amc matador</td>\n",
       "      <td>5.9520</td>\n",
       "      <td>1665.5898</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>amc matador</td>\n",
       "      <td>6.8023</td>\n",
       "      <td>1647.4461</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>amc matador</td>\n",
       "      <td>6.3772</td>\n",
       "      <td>1691.8982</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3962.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>amc matador</td>\n",
       "      <td>6.5897</td>\n",
       "      <td>1797.1315</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cyl    Dis     HP  Weight   Acc  Model_year  Origin     Car_name  \\\n",
       "37   18.0    6  232.0  100.0  3288.0  15.5          71       1  amc matador   \n",
       "86   14.0    8  304.0  150.0  3672.0  11.5          73       1  amc matador   \n",
       "134  16.0    6  258.0  110.0  3632.0  18.0          74       1  amc matador   \n",
       "162  15.0    6  258.0  110.0  3730.0  19.0          75       1  amc matador   \n",
       "189  15.5    8  304.0  120.0  3962.0  13.9          76       1  amc matador   \n",
       "\n",
       "     Mpg_kr  Weight_KG  Accinter country  \n",
       "37   7.6526  1491.4105         0     USA  \n",
       "86   5.9520  1665.5898         0     USA  \n",
       "134  6.8023  1647.4461         0     USA  \n",
       "162  6.3772  1691.8982         1     USA  \n",
       "189  6.5897  1797.1315         1     USA  "
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amc matador\n",
    "autompg_df[autompg_df.Car_name=='amc matador']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cyl</th>\n",
       "      <th>Dis</th>\n",
       "      <th>HP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Model_year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Car_name</th>\n",
       "      <th>Mpg_kr</th>\n",
       "      <th>Weight_KG</th>\n",
       "      <th>Accinter</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2587.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "      <td>8.9280</td>\n",
       "      <td>1173.4425</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "      <td>7.6526</td>\n",
       "      <td>1370.3014</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2875.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "      <td>8.9280</td>\n",
       "      <td>1304.0770</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "      <td>6.3772</td>\n",
       "      <td>1432.4435</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3012.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "      <td>10.2034</td>\n",
       "      <td>1366.2191</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cyl    Dis     HP  Weight   Acc  Model_year  Origin       Car_name  \\\n",
       "17   21.0    6  200.0   85.0  2587.0  16.0          70       1  ford maverick   \n",
       "100  18.0    6  250.0   88.0  3021.0  16.5          73       1  ford maverick   \n",
       "126  21.0    6  200.0  140.0  2875.0  17.0          74       1  ford maverick   \n",
       "155  15.0    6  250.0   72.0  3158.0  19.5          75       1  ford maverick   \n",
       "193  24.0    6  200.0   81.0  3012.0  17.6          76       1  ford maverick   \n",
       "\n",
       "      Mpg_kr  Weight_KG  Accinter country  \n",
       "17    8.9280  1173.4425         0     USA  \n",
       "100   7.6526  1370.3014         0     USA  \n",
       "126   8.9280  1304.0770         0     USA  \n",
       "155   6.3772  1432.4435         1     USA  \n",
       "193  10.2034  1366.2191         1     USA  "
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ford maverick\n",
    "autompg_df[autompg_df.Car_name=='ford maverick']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ford pinto에서 물음표가 있음을 확인\n",
    "- Car_name이 같아도 Model_year도가 다르면 다른 차라고 보는 거 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련에 사용할 데프 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 열삭제\n",
    "new_autompg_df=autompg_df.iloc[:,[9,1,2,3,10,11,6,7,12,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Mpg_kr      398 non-null    float64\n",
      " 1   Cyl         398 non-null    int64  \n",
      " 2   Dis         398 non-null    float64\n",
      " 3   HP          398 non-null    float64\n",
      " 4   Weight_KG   398 non-null    float64\n",
      " 5   Accinter    398 non-null    int32  \n",
      " 6   Model_year  398 non-null    int64  \n",
      " 7   Origin      398 non-null    int64  \n",
      " 8   country     398 non-null    object \n",
      " 9   Car_name    398 non-null    object \n",
      "dtypes: float64(4), int32(1), int64(3), object(2)\n",
      "memory usage: 29.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# 새로 만든 데프 정보확인\n",
    "new_autompg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mpg_kr        1.000000\n",
       "Cyl          -0.775395\n",
       "Dis          -0.804202\n",
       "HP           -0.778060\n",
       "Weight_KG    -0.831740\n",
       "Accinter      0.552626\n",
       "Model_year    0.579267\n",
       "Origin        0.563450\n",
       "Name: Mpg_kr, dtype: float64"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상관계수\n",
    "new_autompg_df.corr()['Mpg_kr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이제 분석 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 모델을 찾는 함수\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "def op_model(col):\n",
    "    data=new_autompg_df.drop(col,axis=1)\n",
    "    target=new_autompg_df.Mpg_kr\n",
    "\n",
    "    ss=StandardScaler()\n",
    "    scal_data=ss.fit_transform(data.iloc[:,:-2])\n",
    "\n",
    "    train_scal_data,test_scal_data,train_target,test_target=train_test_split(scal_data,target,random_state=42)\n",
    "\n",
    "    result=[]\n",
    "    models=all_estimators('regressor')\n",
    "    for name,model in models:\n",
    "        try:\n",
    "            md=model()\n",
    "            md.fit(train_scal_data,train_target)\n",
    "            result.append((name,md.score(train_scal_data,train_target),md.score(test_scal_data,test_target)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    op_sco=pd.DataFrame(result,columns=['model','train','test']).sort_values('test',ascending=False)\n",
    "    return op_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 타겟 나누기\n",
    "data=new_autompg_df.drop('Mpg_kr',axis=1)\n",
    "target=new_autompg_df.Mpg_kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss=StandardScaler()\n",
    "scal_data=ss.fit_transform(data.iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련/테스트 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scal_data,test_scal_data,train_target,test_target=train_test_split(scal_data,target,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    }
   ],
   "source": [
    "# 최적모델 찾기\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "result=[]\n",
    "models=all_estimators('regressor')\n",
    "for name,model in models:\n",
    "    try:\n",
    "        md=model()\n",
    "        md.fit(train_scal_data,train_target)\n",
    "        result.append((name,md.score(train_scal_data,train_target),md.score(test_scal_data,test_target)))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.872287</td>\n",
       "      <td>0.906612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>0.878236</td>\n",
       "      <td>0.905472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.949541</td>\n",
       "      <td>0.890741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.980729</td>\n",
       "      <td>0.885871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.879830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.967540</td>\n",
       "      <td>0.876268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.894048</td>\n",
       "      <td>0.873150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>0.972198</td>\n",
       "      <td>0.868832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GammaRegressor</td>\n",
       "      <td>0.820817</td>\n",
       "      <td>0.857652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.902559</td>\n",
       "      <td>0.844293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>0.810501</td>\n",
       "      <td>0.840391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.815185</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TransformedTargetRegressor</td>\n",
       "      <td>0.815185</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.815131</td>\n",
       "      <td>0.838590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.815131</td>\n",
       "      <td>0.838590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>0.814897</td>\n",
       "      <td>0.837558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LarsCV</td>\n",
       "      <td>0.781283</td>\n",
       "      <td>0.837345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LassoLarsCV</td>\n",
       "      <td>0.813749</td>\n",
       "      <td>0.835343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.813769</td>\n",
       "      <td>0.835112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARDRegression</td>\n",
       "      <td>0.813429</td>\n",
       "      <td>0.834834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LassoLarsIC</td>\n",
       "      <td>0.813812</td>\n",
       "      <td>0.834584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNetCV</td>\n",
       "      <td>0.813536</td>\n",
       "      <td>0.834383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>OrthogonalMatchingPursuitCV</td>\n",
       "      <td>0.813862</td>\n",
       "      <td>0.832990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>0.802638</td>\n",
       "      <td>0.831194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.813215</td>\n",
       "      <td>0.829878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TheilSenRegressor</td>\n",
       "      <td>0.805161</td>\n",
       "      <td>0.817836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>0.758171</td>\n",
       "      <td>0.808843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PLSRegression</td>\n",
       "      <td>0.788159</td>\n",
       "      <td>0.807021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.717888</td>\n",
       "      <td>0.780694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RANSACRegressor</td>\n",
       "      <td>0.752464</td>\n",
       "      <td>0.771021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PassiveAggressiveRegressor</td>\n",
       "      <td>0.781009</td>\n",
       "      <td>0.768366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.767998</td>\n",
       "      <td>0.755397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.657396</td>\n",
       "      <td>0.731320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>OrthogonalMatchingPursuit</td>\n",
       "      <td>0.680362</td>\n",
       "      <td>0.727722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lars</td>\n",
       "      <td>-0.036180</td>\n",
       "      <td>0.050854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DummyRegressor</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LassoLars</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>QuantileRegressor</td>\n",
       "      <td>-0.024149</td>\n",
       "      <td>-0.024439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KernelRidge</td>\n",
       "      <td>-7.961472</td>\n",
       "      <td>-9.549808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GaussianProcessRegressor</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-372.850680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model     train        test\n",
       "39                            SVR  0.872287    0.906612\n",
       "27                          NuSVR  0.878236    0.905472\n",
       "13  HistGradientBoostingRegressor  0.949541    0.890741\n",
       "35          RandomForestRegressor  0.980729    0.885871\n",
       "32               PoissonRegressor  0.861531    0.879830\n",
       "12      GradientBoostingRegressor  0.967540    0.876268\n",
       "15            KNeighborsRegressor  0.894048    0.873150\n",
       "2                BaggingRegressor  0.972198    0.868832\n",
       "9             ExtraTreesRegressor  1.000000    0.859573\n",
       "10                 GammaRegressor  0.820817    0.857652\n",
       "1               AdaBoostRegressor  0.902559    0.844293\n",
       "14                 HuberRegressor  0.810501    0.840391\n",
       "24               LinearRegression  0.815185    0.839378\n",
       "41     TransformedTargetRegressor  0.815185    0.839378\n",
       "37                        RidgeCV  0.815131    0.838590\n",
       "36                          Ridge  0.815131    0.838590\n",
       "3                   BayesianRidge  0.814897    0.837558\n",
       "18                         LarsCV  0.781283    0.837345\n",
       "22                    LassoLarsCV  0.813749    0.835343\n",
       "20                        LassoCV  0.813769    0.835112\n",
       "0                   ARDRegression  0.813429    0.834834\n",
       "23                    LassoLarsIC  0.813812    0.834584\n",
       "7                    ElasticNetCV  0.813536    0.834383\n",
       "29    OrthogonalMatchingPursuitCV  0.813862    0.832990\n",
       "25                      LinearSVR  0.802638    0.831194\n",
       "38                   SGDRegressor  0.813215    0.829878\n",
       "40              TheilSenRegressor  0.805161    0.817836\n",
       "42               TweedieRegressor  0.758171    0.808843\n",
       "30                  PLSRegression  0.788159    0.807021\n",
       "6                      ElasticNet  0.717888    0.780694\n",
       "4           DecisionTreeRegressor  1.000000    0.776873\n",
       "34                RANSACRegressor  0.752464    0.771021\n",
       "31     PassiveAggressiveRegressor  0.781009    0.768366\n",
       "26                   MLPRegressor  0.767998    0.755397\n",
       "19                          Lasso  0.657396    0.731320\n",
       "28      OrthogonalMatchingPursuit  0.680362    0.727722\n",
       "8              ExtraTreeRegressor  1.000000    0.719239\n",
       "17                           Lars -0.036180    0.050854\n",
       "5                  DummyRegressor  0.000000   -0.000042\n",
       "21                      LassoLars  0.000000   -0.000042\n",
       "33              QuantileRegressor -0.024149   -0.024439\n",
       "16                    KernelRidge -7.961472   -9.549808\n",
       "11       GaussianProcessRegressor  1.000000 -372.850680"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적모델 찾기위해 데프로 바꾸고 내림차순\n",
    "op_sco=pd.DataFrame(result,columns=['model','train','test']).sort_values('test',ascending=False)\n",
    "op_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            model     train        test\n",
      "27                          NuSVR  0.879152    0.911341\n",
      "40                            SVR  0.872975    0.910929\n",
      "35       RadiusNeighborsRegressor  0.878179    0.894528\n",
      "13  HistGradientBoostingRegressor  0.948863    0.890759\n",
      "15            KNeighborsRegressor  0.910750    0.885749\n",
      "32               PoissonRegressor  0.858487    0.882125\n",
      "36          RandomForestRegressor  0.982030    0.881284\n",
      "9             ExtraTreesRegressor  1.000000    0.878865\n",
      "12      GradientBoostingRegressor  0.967393    0.875752\n",
      "2                BaggingRegressor  0.976978    0.858884\n",
      "10                 GammaRegressor  0.805893    0.849363\n",
      "18                         LarsCV  0.804412    0.849193\n",
      "1               AdaBoostRegressor  0.906379    0.845783\n",
      "14                 HuberRegressor  0.808375    0.842670\n",
      "24               LinearRegression  0.813237    0.841734\n",
      "42     TransformedTargetRegressor  0.813237    0.841734\n",
      "37                          Ridge  0.813181    0.841169\n",
      "38                        RidgeCV  0.813181    0.841169\n",
      "3                   BayesianRidge  0.813053    0.840712\n",
      "23                    LassoLarsIC  0.813068    0.839375\n",
      "20                        LassoCV  0.811673    0.837823\n",
      "22                    LassoLarsCV  0.811716    0.837452\n",
      "7                    ElasticNetCV  0.811472    0.837309\n",
      "25                      LinearSVR  0.798588    0.836035\n",
      "0                   ARDRegression  0.811379    0.835908\n",
      "29    OrthogonalMatchingPursuitCV  0.811117    0.835078\n",
      "39                   SGDRegressor  0.811932    0.834986\n",
      "41              TheilSenRegressor  0.797230    0.814475\n",
      "30                  PLSRegression  0.787151    0.812287\n",
      "43               TweedieRegressor  0.742027    0.799557\n",
      "34                RANSACRegressor  0.743986    0.795596\n",
      "6                      ElasticNet  0.706413    0.774296\n",
      "4           DecisionTreeRegressor  1.000000    0.768891\n",
      "31     PassiveAggressiveRegressor  0.684900    0.753846\n",
      "19                          Lasso  0.657396    0.731320\n",
      "28      OrthogonalMatchingPursuit  0.680362    0.727722\n",
      "8              ExtraTreeRegressor  1.000000    0.723910\n",
      "26                   MLPRegressor  0.717136    0.666223\n",
      "5                  DummyRegressor  0.000000   -0.000042\n",
      "21                      LassoLars  0.000000   -0.000042\n",
      "33              QuantileRegressor -0.024149   -0.024439\n",
      "17                           Lars -0.207449   -0.122187\n",
      "16                    KernelRidge -7.973668   -9.484334\n",
      "11       GaussianProcessRegressor  1.000000 -288.812012\n"
     ]
    }
   ],
   "source": [
    "# 내가 생각하는 열빼고 최적화모델 구해보기\n",
    "a=op_model(['Mpg_kr','Accinter'])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성 및 훈련\n",
    "from sklearn.svm import NuSVR\n",
    "nusvr=NuSVR().fit(train_scal_data,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 파라미터 찾기\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param={'nu':np.arange(0,1.1,0.1),\n",
    "       'C':[0.1,0.5,1,2,5,10,100,1000],\n",
    "       'tol':[0.0001,0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "gridmodel=GridSearchCV(NuSVR(),param_grid=param,cv=6,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "384 fits failed out of a total of 4224.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "384 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py\", line 251, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py\", line 333, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: nu <= 0 or nu > 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [            nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  1.81435522e-01  1.81459306e-01  1.81662813e-01  1.81137839e-01\n",
      "  1.40465605e-01 -1.98319134e-01 -2.90907728e-01 -2.90907728e-01\n",
      "  4.18490418e-01  4.18504779e-01  4.18591354e-01  4.18871285e-01\n",
      "  3.94730973e-01 -2.70632041e-02 -3.63978277e-01 -3.63978277e-01\n",
      "  5.29706895e-01  5.29696810e-01  5.29736366e-01  5.31360063e-01\n",
      "  4.97033338e-01 -6.96242044e-01 -1.98922261e+00 -1.98922261e+00\n",
      "  5.92692595e-01  5.92697959e-01  5.92774065e-01  5.91609733e-01\n",
      "  5.73041145e-01 -6.71669635e-02 -4.28290724e-01 -4.28290724e-01\n",
      "  6.54547859e-01  6.54545607e-01  6.54678586e-01  6.54735134e-01\n",
      "  6.20586097e-01 -7.33953699e-01 -8.83624643e-01 -8.83624643e-01\n",
      "  6.77234833e-01  6.77238096e-01  6.77257870e-01  6.74813277e-01\n",
      "  6.32791413e-01 -1.08287916e+00 -1.50613110e+00 -1.50613110e+00\n",
      "  6.89737753e-01  6.89754076e-01  6.89854494e-01  6.89673455e-01\n",
      "  6.51988224e-01 -1.20024247e-01 -3.88532523e-01 -3.88532523e-01\n",
      "  6.99324730e-01  6.99324145e-01  6.99598376e-01  6.99223300e-01\n",
      "  6.56788108e-01 -6.70445569e-02 -4.19198285e+00 -4.19198285e+00\n",
      "  7.05403888e-01  7.05409570e-01  7.05381183e-01  7.06825572e-01\n",
      "  6.42956224e-01 -8.43068495e-01 -9.78884519e-01 -9.78884519e-01\n",
      "  7.04918987e-01  7.04922991e-01  7.05070249e-01  7.05303208e-01\n",
      "  6.37017587e-01 -8.26816377e-01 -1.16493664e+00 -1.16493664e+00\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  6.39862757e-01  6.39849592e-01  6.39933599e-01  6.38591741e-01\n",
      "  6.23262481e-01  3.42213888e-02 -2.90907728e-01 -2.90907728e-01\n",
      "  7.76874053e-01  7.76881289e-01  7.76935133e-01  7.76534318e-01\n",
      "  7.70776148e-01  1.66053413e-01 -3.63978277e-01 -3.63978277e-01\n",
      "  8.17373987e-01  8.17372179e-01  8.17325881e-01  8.17221327e-01\n",
      "  8.09499884e-01 -9.49528954e-01 -1.98922261e+00 -1.98922261e+00\n",
      "  8.22823156e-01  8.22821749e-01  8.22813923e-01  8.22906418e-01\n",
      "  8.20199834e-01  2.14123847e-01 -4.28290724e-01 -4.28290724e-01\n",
      "  8.26167951e-01  8.26171042e-01  8.26142044e-01  8.26266133e-01\n",
      "  8.20595161e-01  1.62569962e-01 -3.83918813e-01 -3.83918813e-01\n",
      "  8.28941358e-01  8.28931758e-01  8.28833010e-01  8.29491789e-01\n",
      "  8.19147460e-01 -2.51331965e-01 -1.50613110e+00 -1.50613110e+00\n",
      "  8.30861870e-01  8.30852914e-01  8.30747951e-01  8.29901806e-01\n",
      "  8.27016043e-01  2.61694717e-02 -3.88532523e-01 -3.88532523e-01\n",
      "  8.31651230e-01  8.31652957e-01  8.31655904e-01  8.30748771e-01\n",
      "  8.24197283e-01 -9.99714101e-02 -4.19198285e+00 -4.19198285e+00\n",
      "  8.31913231e-01  8.31916368e-01  8.31960944e-01  8.31559738e-01\n",
      "  8.20711129e-01 -5.88578055e-01 -9.78884519e-01 -9.78884519e-01\n",
      "  8.30670676e-01  8.30673477e-01  8.30682996e-01  8.30307401e-01\n",
      "  8.11396666e-01  1.68152908e-01 -4.09236570e-01 -4.09236570e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  7.77423792e-01  7.77438260e-01  7.77340859e-01  7.75738798e-01\n",
      "  7.65162401e-01  2.72403183e-01 -2.90907728e-01 -2.90907728e-01\n",
      "  8.30973819e-01  8.30975946e-01  8.30895943e-01  8.31059110e-01\n",
      "  8.24058377e-01  3.08782645e-01 -3.63978277e-01 -3.63978277e-01\n",
      "  8.42755751e-01  8.42759716e-01  8.42788518e-01  8.42614495e-01\n",
      "  8.40495316e-01 -5.18077588e-01 -1.98922261e+00 -1.98922261e+00\n",
      "  8.44618369e-01  8.44614735e-01  8.44587461e-01  8.44554987e-01\n",
      "  8.39728711e-01 -3.77497897e-04 -4.28290724e-01 -4.28290724e-01\n",
      "  8.48595065e-01  8.48606392e-01  8.48678058e-01  8.48548038e-01\n",
      "  8.37859879e-01  3.17940134e-01 -3.83918813e-01 -3.83918813e-01\n",
      "  8.48329943e-01  8.48333412e-01  8.48333741e-01  8.48311302e-01\n",
      "  8.44935004e-01 -4.01306860e-01 -1.50613110e+00 -1.50613110e+00\n",
      "  8.48762951e-01  8.48761613e-01  8.48681269e-01  8.48292798e-01\n",
      "  8.42308935e-01  1.33895459e-01 -3.88532523e-01 -3.88532523e-01\n",
      "  8.46932951e-01  8.46932283e-01  8.46832424e-01  8.47140416e-01\n",
      "  8.44654796e-01  1.75160904e-01 -4.19198285e+00 -4.19198285e+00\n",
      "  8.46481561e-01  8.46489459e-01  8.46505815e-01  8.46754739e-01\n",
      "  8.39092385e-01 -2.28807327e-01 -9.78884519e-01 -9.78884519e-01\n",
      "  8.47708513e-01  8.47708870e-01  8.47748659e-01  8.48375872e-01\n",
      "  8.45901043e-01  2.61107575e-01 -4.09236570e-01 -4.09236570e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.28946642e-01  8.28954849e-01  8.28992491e-01  8.29470941e-01\n",
      "  8.29290424e-01  3.14498745e-01 -2.90907728e-01 -2.90907728e-01\n",
      "  8.48890739e-01  8.48900612e-01  8.48876466e-01  8.48906909e-01\n",
      "  8.47524545e-01  2.67703942e-01 -3.63978277e-01 -3.63978277e-01\n",
      "  8.55863382e-01  8.55863899e-01  8.55825936e-01  8.55863006e-01\n",
      "  8.57843052e-01 -2.22383394e-01 -1.98922261e+00 -1.98922261e+00\n",
      "  8.57404260e-01  8.57400243e-01  8.57398527e-01  8.56731694e-01\n",
      "  8.52798840e-01  6.17113434e-02 -4.28290724e-01 -4.28290724e-01\n",
      "  8.57874028e-01  8.57872751e-01  8.57878040e-01  8.57888131e-01\n",
      "  8.55024664e-01  4.17944322e-01 -3.83918813e-01 -3.83918813e-01\n",
      "  8.55670181e-01  8.55660488e-01  8.55562766e-01  8.54904659e-01\n",
      "  8.48675101e-01 -1.11870888e-01 -1.50613110e+00 -1.50613110e+00\n",
      "  8.52949385e-01  8.52955497e-01  8.52961746e-01  8.52754697e-01\n",
      "  8.51739221e-01  2.23415915e-01 -3.88532523e-01 -3.88532523e-01\n",
      "  8.50789969e-01  8.50793686e-01  8.50890257e-01  8.51146558e-01\n",
      "  8.41957213e-01  2.09744890e-01 -4.19198285e+00 -4.19198285e+00\n",
      "  8.46178629e-01  8.46176063e-01  8.46102727e-01  8.45632220e-01\n",
      "  8.43156918e-01 -3.11998537e-01 -9.78884519e-01 -9.78884519e-01\n",
      "  8.45740154e-01  8.45734381e-01  8.45749391e-01  8.45425577e-01\n",
      "  8.48223869e-01  3.96131787e-01 -4.09236570e-01 -4.09236570e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.36289621e-01  8.36300187e-01  8.36355413e-01  8.36844167e-01\n",
      "  8.40836898e-01  7.17984733e-01 -2.90907728e-01 -2.90907728e-01\n",
      "  8.57681349e-01  8.57683044e-01  8.57663426e-01  8.57629790e-01\n",
      "  8.51558194e-01  6.98177303e-01 -3.63978277e-01 -3.63978277e-01\n",
      "  8.63618378e-01  8.63616393e-01  8.63584837e-01  8.62897244e-01\n",
      "  8.60791704e-01  5.57271433e-01 -1.98922261e+00 -1.98922261e+00\n",
      "  8.61627647e-01  8.61630737e-01  8.61662878e-01  8.61574662e-01\n",
      "  8.55553081e-01  4.17986832e-01 -4.28290724e-01 -4.28290724e-01\n",
      "  8.61043592e-01  8.61035838e-01  8.61003928e-01  8.60487979e-01\n",
      "  8.55875114e-01  6.35086462e-01 -3.83918813e-01 -3.83918813e-01\n",
      "  8.60295924e-01  8.60304226e-01  8.60341064e-01  8.60005088e-01\n",
      "  8.59786355e-01  6.87035864e-01 -1.50613110e+00 -1.50613110e+00\n",
      "  8.55880114e-01  8.55886077e-01  8.55968204e-01  8.56525010e-01\n",
      "  8.54227128e-01  4.58559117e-01 -3.88532523e-01 -3.88532523e-01\n",
      "  8.51823719e-01  8.51820741e-01  8.51784935e-01  8.51836618e-01\n",
      "  8.54853190e-01  5.95918644e-01 -4.19198285e+00 -4.19198285e+00\n",
      "  8.47890663e-01  8.47909783e-01  8.48084767e-01  8.48215045e-01\n",
      "  8.44938539e-01  4.04992537e-01 -9.78884519e-01 -9.78884519e-01\n",
      "  8.47594051e-01  8.47590177e-01  8.47570264e-01  8.47378349e-01\n",
      "  8.48442341e-01  7.16487307e-01 -4.09236570e-01 -4.09236570e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.38364511e-01  8.38372428e-01  8.38501539e-01  8.38602852e-01\n",
      "  8.43376134e-01  7.00419699e-01 -2.90907728e-01 -2.90907728e-01\n",
      "  8.65436529e-01  8.65438616e-01  8.65498102e-01  8.65591755e-01\n",
      "  8.58063384e-01  6.55616395e-01 -3.63978277e-01 -3.63978277e-01\n",
      "  8.68283544e-01  8.68282161e-01  8.68303568e-01  8.68589408e-01\n",
      "  8.66353142e-01  5.24582526e-01 -1.98922261e+00 -1.98922261e+00\n",
      "  8.62139086e-01  8.62126958e-01  8.62099429e-01  8.62025051e-01\n",
      "  8.56554585e-01  6.72511317e-01 -4.28290724e-01 -4.28290724e-01\n",
      "  8.61411098e-01  8.61415098e-01  8.61436272e-01  8.61615879e-01\n",
      "  8.60516117e-01  7.10079326e-01 -3.83918813e-01 -3.83918813e-01\n",
      "  8.59392075e-01  8.59391907e-01  8.59306349e-01  8.59076449e-01\n",
      "  8.54991391e-01  6.60903528e-01 -1.50613110e+00 -1.50613110e+00\n",
      "  8.56952278e-01  8.56953011e-01  8.56960542e-01  8.57214971e-01\n",
      "  8.54678369e-01  6.57000313e-01 -3.88532523e-01 -3.88532523e-01\n",
      "  8.52458326e-01  8.52462560e-01  8.52465800e-01  8.52605781e-01\n",
      "  8.51592984e-01  5.66085580e-01 -4.19198285e+00 -4.19198285e+00\n",
      "  8.52337195e-01  8.52328942e-01  8.52431085e-01  8.52046078e-01\n",
      "  8.52410960e-01  5.96214011e-01 -9.78884519e-01 -9.78884519e-01\n",
      "  8.52335901e-01  8.52322344e-01  8.52255315e-01  8.51296763e-01\n",
      "  8.49450966e-01  6.31514429e-01 -4.09236570e-01 -4.09236570e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.48544699e-01  8.48553290e-01  8.48559172e-01  8.48965084e-01\n",
      "  8.51161222e-01  5.63992520e-01 -2.90907728e-01 -2.90907728e-01\n",
      "  8.62070190e-01  8.62062010e-01  8.61945582e-01  8.61037373e-01\n",
      "  8.57445820e-01  4.98839027e-01 -3.63978277e-01 -3.63978277e-01\n",
      "  8.63938775e-01  8.63949214e-01  8.63924858e-01  8.63110241e-01\n",
      "  8.60217023e-01  5.87438517e-01 -1.98922261e+00 -1.98922261e+00\n",
      "  8.60731909e-01  8.60732855e-01  8.60747310e-01  8.60618816e-01\n",
      "  8.51638632e-01  4.05538483e-01 -4.28290724e-01 -4.28290724e-01\n",
      "  8.59666943e-01  8.59671133e-01  8.59692471e-01  8.61381441e-01\n",
      "  8.59797762e-01  6.56723375e-01 -3.83918813e-01 -3.83918813e-01\n",
      "  8.62925677e-01  8.62931277e-01  8.63033455e-01  8.63301213e-01\n",
      "  8.59137711e-01  6.11688386e-01 -1.50613110e+00 -1.50613110e+00\n",
      "  8.60769414e-01  8.60765618e-01  8.60738760e-01  8.60502783e-01\n",
      "  8.60616179e-01  5.15838017e-01 -3.88532523e-01 -3.88532523e-01\n",
      "  8.55885385e-01  8.55893990e-01  8.55981288e-01  8.58584982e-01\n",
      "  8.58691688e-01  5.52178557e-01 -4.19198285e+00 -4.19198285e+00\n",
      "  8.55643301e-01  8.55657941e-01  8.55750697e-01  8.56962729e-01\n",
      "  8.58820931e-01  6.05085594e-01 -9.78884519e-01 -9.78884519e-01\n",
      "  8.55642793e-01  8.55647651e-01  8.55781931e-01  8.56731901e-01\n",
      "  8.58002301e-01  4.30584639e-01 -4.09236570e-01 -4.09236570e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.07969755e-01  8.08030051e-01  8.08438999e-01  8.09198136e-01\n",
      "  8.14162966e-01  4.21454561e-01 -2.90907728e-01 -2.90907728e-01\n",
      "  8.08625241e-01  8.08604041e-01  8.08253370e-01  8.06060099e-01\n",
      "  8.11346931e-01  5.31234119e-01 -3.63978277e-01 -3.63978277e-01\n",
      "  8.18536867e-01  8.18578677e-01  8.19207031e-01  8.19456145e-01\n",
      "  8.17645886e-01  4.92044085e-01 -1.98922261e+00 -1.98922261e+00\n",
      "  8.16448720e-01  8.16408095e-01  8.16179390e-01  8.17612141e-01\n",
      "  8.27325896e-01  5.97132573e-01 -4.28290724e-01 -4.28290724e-01\n",
      "  8.21077384e-01  8.21086281e-01  8.21269774e-01  8.25306621e-01\n",
      "  8.26227742e-01  5.73260299e-01 -3.83918813e-01 -3.83918813e-01\n",
      "  8.12849863e-01  8.12866175e-01  8.13050180e-01  8.16284819e-01\n",
      "  8.18214010e-01  5.56925764e-01 -1.50613110e+00 -1.50613110e+00\n",
      "  8.10894916e-01  8.10917641e-01  8.11336711e-01  8.13838727e-01\n",
      "  8.17265280e-01  4.36794059e-01 -3.88532523e-01 -3.88532523e-01\n",
      "  8.10893731e-01  8.10908566e-01  8.10978529e-01  8.14241178e-01\n",
      "  8.23092576e-01  5.15855332e-01 -4.19198285e+00 -4.19198285e+00\n",
      "  8.10890094e-01  8.10894177e-01  8.10883483e-01  8.15012599e-01\n",
      "  8.20355326e-01  5.32114151e-01 -9.78884519e-01 -9.78884519e-01\n",
      "  8.10893570e-01  8.10939563e-01  8.10918685e-01  8.14437095e-01\n",
      "  8.17259276e-01  5.36253821e-01 -4.09236570e-01 -4.09236570e-01]\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [            nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  2.15748679e-01  2.15768097e-01  2.15987907e-01  2.15460165e-01\n",
      "  1.80765294e-01 -2.47267193e-01 -3.44439265e-01 -3.44439265e-01\n",
      "  4.42638551e-01  4.42647332e-01  4.42681301e-01  4.42580473e-01\n",
      "  4.18498964e-01 -5.17293564e-02 -4.22972013e-01 -4.22972013e-01\n",
      "  5.54365378e-01  5.54357372e-01  5.54388071e-01  5.55534258e-01\n",
      "  5.31114830e-01 -8.42002802e-01 -1.78680068e+00 -1.78680068e+00\n",
      "  6.15878899e-01  6.15883212e-01  6.15918183e-01  6.15417483e-01\n",
      "  5.95798042e-01 -1.29027982e-01 -4.58785213e-01 -4.58785213e-01\n",
      "  6.73440985e-01  6.73441719e-01  6.73522894e-01  6.73834712e-01\n",
      "  6.42885922e-01 -6.18611189e-01 -7.67163359e-01 -7.67163359e-01\n",
      "  6.97152292e-01  6.97151286e-01  6.97106854e-01  6.95285179e-01\n",
      "  6.58527296e-01 -1.09777164e+00 -1.46375938e+00 -1.46375938e+00\n",
      "  7.10100460e-01  7.10118337e-01  7.10162686e-01  7.10295318e-01\n",
      "  6.83047111e-01 -1.13128026e-01 -3.28856491e-01 -3.28856491e-01\n",
      "  7.19567916e-01  7.19571007e-01  7.19795467e-01  7.19738195e-01\n",
      "  6.78003277e-01 -5.65588294e-02 -3.80421539e+00 -3.80421539e+00\n",
      "  7.23144447e-01  7.23147086e-01  7.23153021e-01  7.23701188e-01\n",
      "  6.66127416e-01 -6.88433228e-01 -8.08990624e-01 -8.08990624e-01\n",
      "  7.21126374e-01  7.21129503e-01  7.21256679e-01  7.21600449e-01\n",
      "  6.63976715e-01 -6.41812318e-01 -9.42827983e-01 -9.42827983e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  6.67354314e-01  6.67339450e-01  6.67332585e-01  6.66575815e-01\n",
      "  6.48622512e-01 -1.18834743e-03 -3.44439265e-01 -3.44439265e-01\n",
      "  7.99279537e-01  7.99285679e-01  7.99337334e-01  7.99041520e-01\n",
      "  7.89289142e-01  1.46204206e-01 -4.22972013e-01 -4.22972013e-01\n",
      "  8.37241066e-01  8.37240866e-01  8.37240399e-01  8.36742689e-01\n",
      "  8.28600092e-01 -8.46635764e-01 -1.78680068e+00 -1.78680068e+00\n",
      "  8.44544426e-01  8.44541865e-01  8.44524877e-01  8.44224887e-01\n",
      "  8.39615099e-01  2.30135796e-01 -4.58785213e-01 -4.58785213e-01\n",
      "  8.47379263e-01  8.47379545e-01  8.47411006e-01  8.47416713e-01\n",
      "  8.41604699e-01  1.79042192e-01 -3.19066626e-01 -3.19066626e-01\n",
      "  8.46251844e-01  8.46248750e-01  8.46226456e-01  8.46161803e-01\n",
      "  8.37065184e-01 -3.01974121e-01 -1.46375938e+00 -1.46375938e+00\n",
      "  8.48948688e-01  8.48942389e-01  8.48884277e-01  8.48140187e-01\n",
      "  8.41977179e-01  6.91047431e-02 -3.28856491e-01 -3.28856491e-01\n",
      "  8.50479190e-01  8.50478459e-01  8.50483334e-01  8.50206555e-01\n",
      "  8.38112506e-01 -2.36501643e-01 -3.80421539e+00 -3.80421539e+00\n",
      "  8.51014587e-01  8.51018650e-01  8.51060890e-01  8.50500848e-01\n",
      "  8.42342069e-01 -4.45708045e-01 -8.08990624e-01 -8.08990624e-01\n",
      "  8.50294637e-01  8.50299279e-01  8.50294896e-01  8.50131180e-01\n",
      "  8.31667672e-01  2.05566306e-01 -3.54383239e-01 -3.54383239e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.03859362e-01  8.03865895e-01  8.03784514e-01  8.02451793e-01\n",
      "  7.89069125e-01  2.43130053e-01 -3.44439265e-01 -3.44439265e-01\n",
      "  8.56996148e-01  8.56999323e-01  8.56963777e-01  8.57069119e-01\n",
      "  8.51806664e-01  2.84596165e-01 -4.22972013e-01 -4.22972013e-01\n",
      "  8.68112484e-01  8.68116749e-01  8.68137889e-01  8.68142137e-01\n",
      "  8.65351454e-01 -4.00562025e-01 -1.78680068e+00 -1.78680068e+00\n",
      "  8.72838704e-01  8.72837264e-01  8.72829082e-01  8.72830867e-01\n",
      "  8.66888437e-01  1.27132241e-01 -4.58785213e-01 -4.58785213e-01\n",
      "  8.74380043e-01  8.74382166e-01  8.74402921e-01  8.74198082e-01\n",
      "  8.69678450e-01  3.54051161e-01 -3.19066626e-01 -3.19066626e-01\n",
      "  8.74085524e-01  8.74087795e-01  8.74114671e-01  8.73923641e-01\n",
      "  8.70287472e-01 -4.19896689e-01 -1.46375938e+00 -1.46375938e+00\n",
      "  8.72910170e-01  8.72913290e-01  8.72910954e-01  8.72897380e-01\n",
      "  8.68720640e-01  1.91018791e-01 -3.28856491e-01 -3.28856491e-01\n",
      "  8.71598458e-01  8.71595334e-01  8.71522728e-01  8.72038507e-01\n",
      "  8.65674954e-01  1.95748086e-01 -3.80421539e+00 -3.80421539e+00\n",
      "  8.70572612e-01  8.70570104e-01  8.70571908e-01  8.70739969e-01\n",
      "  8.63173426e-01 -1.44554680e-01 -8.08990624e-01 -8.08990624e-01\n",
      "  8.70767609e-01  8.70770248e-01  8.70777823e-01  8.70777876e-01\n",
      "  8.65329953e-01  2.80846788e-01 -3.54383239e-01 -3.54383239e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.53573248e-01  8.53578692e-01  8.53593081e-01  8.53763555e-01\n",
      "  8.56092893e-01  3.01757943e-01 -3.44439265e-01 -3.44439265e-01\n",
      "  8.77276314e-01  8.77279256e-01  8.77297198e-01  8.77398988e-01\n",
      "  8.74647615e-01  2.76588701e-01 -4.22972013e-01 -4.22972013e-01\n",
      "  8.84475761e-01  8.84475571e-01  8.84457333e-01  8.84319715e-01\n",
      "  8.82110395e-01 -1.48998476e-01 -1.78680068e+00 -1.78680068e+00\n",
      "  8.87275311e-01  8.87278655e-01  8.87299938e-01  8.87236024e-01\n",
      "  8.83540146e-01  4.69340379e-02 -4.58785213e-01 -4.58785213e-01\n",
      "  8.87426488e-01  8.87423672e-01  8.87435159e-01  8.87403108e-01\n",
      "  8.83989210e-01  4.19578531e-01 -3.19066626e-01 -3.19066626e-01\n",
      "  8.86821925e-01  8.86822464e-01  8.86840213e-01  8.86771408e-01\n",
      "  8.82054854e-01 -9.09981798e-02 -1.46375938e+00 -1.46375938e+00\n",
      "  8.86895372e-01  8.86894298e-01  8.86889070e-01  8.86781761e-01\n",
      "  8.82173673e-01  2.86236258e-01 -3.28856491e-01 -3.28856491e-01\n",
      "  8.84983030e-01  8.84976070e-01  8.84958752e-01  8.84897304e-01\n",
      "  8.81192130e-01  1.48450143e-01 -3.80421539e+00 -3.80421539e+00\n",
      "  8.83685330e-01  8.83685989e-01  8.83664527e-01  8.83596672e-01\n",
      "  8.79584481e-01 -1.88638061e-01 -8.08990624e-01 -8.08990624e-01\n",
      "  8.83790052e-01  8.83793663e-01  8.83803259e-01  8.83911094e-01\n",
      "  8.82650957e-01  4.18349621e-01 -3.54383239e-01 -3.54383239e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.75711851e-01  8.75714798e-01  8.75763111e-01  8.76234499e-01\n",
      "  8.75840352e-01  7.29845800e-01 -3.44439265e-01 -3.44439265e-01\n",
      "  8.93398602e-01  8.93398707e-01  8.93376721e-01  8.93662061e-01\n",
      "  8.92206319e-01  7.19273126e-01 -4.22972013e-01 -4.22972013e-01\n",
      "  8.97539636e-01  8.97541559e-01  8.97549542e-01  8.97453920e-01\n",
      "  8.96342240e-01  5.88330710e-01 -1.78680068e+00 -1.78680068e+00\n",
      "  8.99425874e-01  8.99425845e-01  8.99412748e-01  8.99546739e-01\n",
      "  8.94521460e-01  4.73585117e-01 -4.58785213e-01 -4.58785213e-01\n",
      "  8.99436941e-01  8.99434970e-01  8.99429459e-01  8.99250189e-01\n",
      "  8.95140845e-01  6.97466618e-01 -3.19066626e-01 -3.19066626e-01\n",
      "  8.99487796e-01  8.99486138e-01  8.99484497e-01  8.99523770e-01\n",
      "  8.96628025e-01  6.94579710e-01 -1.46375938e+00 -1.46375938e+00\n",
      "  8.98287029e-01  8.98286904e-01  8.98267227e-01  8.98292845e-01\n",
      "  8.95844881e-01  4.06677724e-01 -3.28856491e-01 -3.28856491e-01\n",
      "  8.97917538e-01  8.97921231e-01  8.97935810e-01  8.97792320e-01\n",
      "  8.95574545e-01  6.20031892e-01 -3.80421539e+00 -3.80421539e+00\n",
      "  8.97230169e-01  8.97230398e-01  8.97226823e-01  8.97172510e-01\n",
      "  8.95055410e-01  4.40203061e-01 -8.08990624e-01 -8.08990624e-01\n",
      "  8.97211141e-01  8.97211405e-01  8.97227880e-01  8.97218556e-01\n",
      "  8.94780908e-01  7.28490928e-01 -3.54383239e-01 -3.54383239e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  8.86469764e-01  8.86474067e-01  8.86517664e-01  8.86608854e-01\n",
      "  8.88938516e-01  7.25923578e-01 -3.44439265e-01 -3.44439265e-01\n",
      "  9.02915749e-01  9.02917791e-01  9.02935933e-01  9.03054328e-01\n",
      "  9.02497755e-01  6.77727038e-01 -4.22972013e-01 -4.22972013e-01\n",
      "  9.07112588e-01  9.07112816e-01  9.07099565e-01  9.07090635e-01\n",
      "  9.05220539e-01  5.94478579e-01 -1.78680068e+00 -1.78680068e+00\n",
      "  9.08577614e-01  9.08577700e-01  9.08573567e-01  9.08700140e-01\n",
      "  9.04831401e-01  6.90015383e-01 -4.58785213e-01 -4.58785213e-01\n",
      "  9.08426055e-01  9.08423502e-01  9.08408513e-01  9.08429692e-01\n",
      "  9.05231961e-01  7.47945011e-01 -3.19066626e-01 -3.19066626e-01\n",
      "  9.08622268e-01  9.08621662e-01  9.08616795e-01  9.08545215e-01\n",
      "  9.05361379e-01  6.64283099e-01 -1.46375938e+00 -1.46375938e+00\n",
      "  9.07920311e-01  9.07920941e-01  9.07928451e-01  9.07931015e-01\n",
      "  9.05577905e-01  6.90649893e-01 -3.28856491e-01 -3.28856491e-01\n",
      "  9.07002381e-01  9.07000546e-01  9.07001254e-01  9.06876662e-01\n",
      "  9.05112862e-01  6.41013904e-01 -3.80421539e+00 -3.80421539e+00\n",
      "  9.06539919e-01  9.06539403e-01  9.06548755e-01  9.06307357e-01\n",
      "  9.05773819e-01  6.48805514e-01 -8.08990624e-01 -8.08990624e-01\n",
      "  9.06538741e-01  9.06538740e-01  9.06539109e-01  9.06553095e-01\n",
      "  9.03707773e-01  6.90005232e-01 -3.54383239e-01 -3.54383239e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  9.15413850e-01  9.15416509e-01  9.15502373e-01  9.16001797e-01\n",
      "  9.17377441e-01  6.33682882e-01 -3.44439265e-01 -3.44439265e-01\n",
      "  9.31932154e-01  9.31933865e-01  9.31966966e-01  9.32339684e-01\n",
      "  9.31632315e-01  5.77669584e-01 -4.22972013e-01 -4.22972013e-01\n",
      "  9.37762661e-01  9.37762847e-01  9.37800289e-01  9.37923736e-01\n",
      "  9.35087980e-01  6.58454890e-01 -1.78680068e+00 -1.78680068e+00\n",
      "  9.39474284e-01  9.39474771e-01  9.39493231e-01  9.39521556e-01\n",
      "  9.38980146e-01  5.27907933e-01 -4.58785213e-01 -4.58785213e-01\n",
      "  9.39752527e-01  9.39753891e-01  9.39770718e-01  9.39794000e-01\n",
      "  9.38255182e-01  7.27264343e-01 -3.19066626e-01 -3.19066626e-01\n",
      "  9.40078031e-01  9.40080611e-01  9.40087702e-01  9.39905617e-01\n",
      "  9.37741335e-01  6.27839807e-01 -1.46375938e+00 -1.46375938e+00\n",
      "  9.39226182e-01  9.39226256e-01  9.39252278e-01  9.39275393e-01\n",
      "  9.35940729e-01  5.65128081e-01 -3.28856491e-01 -3.28856491e-01\n",
      "  9.38400628e-01  9.38405485e-01  9.38445141e-01  9.38760940e-01\n",
      "  9.35957009e-01  6.19165558e-01 -3.80421539e+00 -3.80421539e+00\n",
      "  9.38368856e-01  9.38371483e-01  9.38380995e-01  9.38387888e-01\n",
      "  9.35754897e-01  6.84839618e-01 -8.08990624e-01 -8.08990624e-01\n",
      "  9.38368747e-01  9.38368689e-01  9.38373292e-01  9.38371022e-01\n",
      "  9.36394978e-01  4.92957114e-01 -3.54383239e-01 -3.54383239e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "  9.39920863e-01  9.39922222e-01  9.39971293e-01  9.40580541e-01\n",
      "  9.43638771e-01  4.24712387e-01 -3.44439265e-01 -3.44439265e-01\n",
      "  9.55400307e-01  9.55399926e-01  9.55396576e-01  9.55950841e-01\n",
      "  9.54929192e-01  5.87649741e-01 -4.22972013e-01 -4.22972013e-01\n",
      "  9.60430658e-01  9.60431536e-01  9.60407998e-01  9.60650612e-01\n",
      "  9.59308974e-01  5.67020685e-01 -1.78680068e+00 -1.78680068e+00\n",
      "  9.63151753e-01  9.63150302e-01  9.63138498e-01  9.62976102e-01\n",
      "  9.59669300e-01  6.84276588e-01 -4.58785213e-01 -4.58785213e-01\n",
      "  9.63764847e-01  9.63766477e-01  9.63771736e-01  9.63650248e-01\n",
      "  9.60633159e-01  6.38989664e-01 -3.19066626e-01 -3.19066626e-01\n",
      "  9.62101994e-01  9.62103946e-01  9.62087604e-01  9.62189112e-01\n",
      "  9.60551093e-01  6.45493895e-01 -1.46375938e+00 -1.46375938e+00\n",
      "  9.61019931e-01  9.61026739e-01  9.61102856e-01  9.61555381e-01\n",
      "  9.60832976e-01  5.45854679e-01 -3.28856491e-01 -3.28856491e-01\n",
      "  9.61019441e-01  9.61023320e-01  9.61057688e-01  9.61355008e-01\n",
      "  9.60635254e-01  6.14345883e-01 -3.80421539e+00 -3.80421539e+00\n",
      "  9.61019442e-01  9.61021251e-01  9.61047116e-01  9.61228079e-01\n",
      "  9.60402503e-01  6.51473121e-01 -8.08990624e-01 -8.08990624e-01\n",
      "  9.61019399e-01  9.61019945e-01  9.61020261e-01  9.61187278e-01\n",
      "  9.60141213e-01  6.74416050e-01 -3.54383239e-01 -3.54383239e-01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=6, estimator=NuSVR(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 0.5, 1, 2, 5, 10, 100, 1000],\n",
       "                         &#x27;nu&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "                         &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=6, estimator=NuSVR(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 0.5, 1, 2, 5, 10, 100, 1000],\n",
       "                         &#x27;nu&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "                         &#x27;tol&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: NuSVR</label><div class=\"sk-toggleable__content\"><pre>NuSVR()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NuSVR</label><div class=\"sk-toggleable__content\"><pre>NuSVR()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=6, estimator=NuSVR(),\n",
       "             param_grid={'C': [0.1, 0.5, 1, 2, 5, 10, 100, 1000],\n",
       "                         'nu': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "                         'tol': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적모델/파라미터로 훈련하기\n",
    "gridmodel.fit(train_scal_data,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NuSVR(C=10, nu=0.30000000000000004, tol=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NuSVR</label><div class=\"sk-toggleable__content\"><pre>NuSVR(C=10, nu=0.30000000000000004, tol=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NuSVR(C=10, nu=0.30000000000000004, tol=0.1)"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적의 파라미터값 확인\n",
    "gridmodel.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평가점수는 0.9057949373393069\n",
      "test 평가점수는 0.9200833082896663\n"
     ]
    }
   ],
   "source": [
    "# 평가점수 확인\n",
    "print(f\"train 평가점수는 {gridmodel.score(train_scal_data,train_target)}\")\n",
    "print(f\"test 평가점수는 {gridmodel.score(test_scal_data,test_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 예측값\n",
      "[14.10771839 12.75431346  8.22915774  6.32205064  5.82631703 11.57865918\n",
      " 11.13376085  5.62568395  7.78144027  8.66018078  5.37182831 15.55459974\n",
      " 10.92546546  6.11041392  9.25522408  4.66314915 12.77938061  8.41179521\n",
      "  6.46910375 15.49853273  9.8171318   8.46773463 10.6975053  12.86506791\n",
      "  7.09594037 17.56227675 10.54629443 10.28731903  8.5052404   5.21943587\n",
      " 11.64390769 16.25244824  8.15233025 10.73086553 15.05524019  5.83570207\n",
      "  9.48010097  7.64506977  6.08398992 10.76660747 10.04058019 12.11079205\n",
      "  8.83591498  4.73770166 10.0425468  14.1351026  10.59030046  8.97081722\n",
      " 10.77391253 11.90357475  9.17941943 14.45656067 14.37952638  4.91194969\n",
      " 10.65243851  4.86017676  7.31627643 12.63930838  9.70179712  7.70303921\n",
      "  5.80336456 13.65840748  9.83357484  8.73286031  8.08740696 11.16097692\n",
      " 10.15808372 15.23911397 12.58353884  6.34885146 14.8177323   6.13998397\n",
      "  5.01698646  7.74947732 10.12048447  8.63840408  7.9882261  12.54296539\n",
      " 12.54785392  7.77475228  6.85807211 12.03913999 15.52529523 14.59361657\n",
      "  9.48893334  4.99149372 15.09767185 14.28969746 10.8628198   5.34154917\n",
      "  6.60067699 12.21776272 10.79115264 14.84101082  9.27209012 15.17451611\n",
      " 12.82506621  8.39081548 10.56920591  5.83014324]\n",
      "실제값\n",
      "198    14.0297\n",
      "396    11.9040\n",
      "33      8.0777\n",
      "208     5.5269\n",
      "93      5.9520\n",
      "        ...   \n",
      "378    16.1555\n",
      "371    12.3292\n",
      "280     9.1406\n",
      "323    11.8615\n",
      "75      5.9520\n",
      "Name: Mpg_kr, Length: 100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 예측하기 \n",
    "print(f\"test 예측값\\n{gridmodel.predict(test_scal_data)}\")\n",
    "print(f\"실제값\\n{test_target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RadiusNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 파라미터 찾기\n",
    "param={'radius':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}\n",
    "rnn_grid=GridSearchCV(RadiusNeighborsRegressor(weights='distance'),param_grid=param,cv=5,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 721, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RadiusNeighborsRegressor(weights=&#x27;distance&#x27;),\n",
       "             param_grid={&#x27;radius&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                    0.9]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RadiusNeighborsRegressor(weights=&#x27;distance&#x27;),\n",
       "             param_grid={&#x27;radius&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                    0.9]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RadiusNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>RadiusNeighborsRegressor(weights=&#x27;distance&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RadiusNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>RadiusNeighborsRegressor(weights=&#x27;distance&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RadiusNeighborsRegressor(weights='distance'),\n",
       "             param_grid={'radius': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                    0.9]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "rnn_grid.fit(train_scal_data,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RadiusNeighborsRegressor(radius=0.1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RadiusNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>RadiusNeighborsRegressor(radius=0.1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RadiusNeighborsRegressor(radius=0.1, weights='distance')"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적 파라미터 확인\n",
    "rnn_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평가점수는 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whrjs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_regression.py:482: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\deeplearning\\autompg.ipynb 셀 79\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/deeplearning/autompg.ipynb#Y235sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain 평가점수는 \u001b[39m\u001b[39m{\u001b[39;00mrnn_grid\u001b[39m.\u001b[39mscore(train_scal_data,train_target)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/deeplearning/autompg.ipynb#Y235sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest 평가점수는 \u001b[39m\u001b[39m{\u001b[39;00mrnn_grid\u001b[39m.\u001b[39mscore(test_scal_data,test_target)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:452\u001b[0m, in \u001b[0;36mBaseSearchCV.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m scorer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_, X, y)\n\u001b[0;32m    451\u001b[0m \u001b[39m# callable\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscorer_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_, X, y)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultimetric_:\n\u001b[0;32m    454\u001b[0m     score \u001b[39m=\u001b[39m score[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py:429\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_passthrough_scorer\u001b[39m(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    428\u001b[0m     \u001b[39m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39mscore(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:721\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n\u001b[0;32m    720\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m--> 721\u001b[0m \u001b[39mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:911\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2_score\u001b[39m(\n\u001b[0;32m    785\u001b[0m     y_true,\n\u001b[0;32m    786\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m     force_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    791\u001b[0m ):\n\u001b[0;32m    792\u001b[0m     \u001b[39m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \n\u001b[0;32m    794\u001b[0m \u001b[39m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[39m    -inf\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 911\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    912\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    916\u001b[0m     \u001b[39mif\u001b[39;00m _num_samples(y_pred) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m--> 102\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    105\u001b[0m     y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[0;32m    900\u001b[0m             array,\n\u001b[0;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    904\u001b[0m         )\n\u001b[0;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# 평가점수\n",
    "print(f\"train 평가점수는 {rnn_grid.score(train_scal_data,train_target)}\")\n",
    "print(f\"test 평가점수는 {rnn_grid.score(test_scal_data,test_target)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리에서 NaN없는거 확인 했는데...왜 오류가..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로드\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델생성\n",
    "model=Sequential(name='AUTOMPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 층은 반드시 입력정보 파라미터 설정 => input_shape=(튜플형식) 혹은 input_dim = 숫자\n",
    "l1=Dense(10,activation='relu',input_shape=(7,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째는 결과층으로 값이 1개\n",
    "l2=Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 추가??\n",
    "model.add(l1)\n",
    "model.add(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AUTOMPG\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_67 (Dense)            (None, 10)                80        \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 92.5621 - mse: 92.5621 - mae: 9.0279\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 89.6907 - mse: 89.6907 - mae: 8.8782\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 990us/step - loss: 87.2920 - mse: 87.2920 - mae: 8.7521\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 888us/step - loss: 84.9985 - mse: 84.9985 - mae: 8.6290\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 881us/step - loss: 82.7079 - mse: 82.7079 - mae: 8.5052\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 80.4396 - mse: 80.4396 - mae: 8.3777\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 78.0742 - mse: 78.0742 - mae: 8.2472\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 75.7194 - mse: 75.7194 - mae: 8.1119\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 887us/step - loss: 73.3591 - mse: 73.3591 - mae: 7.9760\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 887us/step - loss: 70.9738 - mse: 70.9738 - mae: 7.8359\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 68.5249 - mse: 68.5249 - mae: 7.6891\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 987us/step - loss: 66.0267 - mse: 66.0267 - mae: 7.5378\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 63.5760 - mse: 63.5760 - mae: 7.3846\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 61.1112 - mse: 61.1112 - mae: 7.2278\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 58.5699 - mse: 58.5699 - mae: 7.0651\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 56.1046 - mse: 56.1046 - mae: 6.9006\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 776us/step - loss: 53.5453 - mse: 53.5453 - mae: 6.7282\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 51.0922 - mse: 51.0922 - mae: 6.5599\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 988us/step - loss: 48.5740 - mse: 48.5740 - mae: 6.3844\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 46.0369 - mse: 46.0369 - mae: 6.2021\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 43.5950 - mse: 43.5950 - mae: 6.0222\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 899us/step - loss: 41.1007 - mse: 41.1007 - mae: 5.8368\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 887us/step - loss: 38.7295 - mse: 38.7295 - mae: 5.6494\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 968us/step - loss: 36.3462 - mse: 36.3462 - mae: 5.4610\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 34.0305 - mse: 34.0305 - mae: 5.2714\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 31.7277 - mse: 31.7277 - mae: 5.0828\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 29.5317 - mse: 29.5317 - mae: 4.8937\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 939us/step - loss: 27.4609 - mse: 27.4609 - mae: 4.7056\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 25.3607 - mse: 25.3607 - mae: 4.5111\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 23.3482 - mse: 23.3482 - mae: 4.3166\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 21.4766 - mse: 21.4766 - mae: 4.1264\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 938us/step - loss: 19.6854 - mse: 19.6854 - mae: 3.9338\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 17.9719 - mse: 17.9719 - mae: 3.7402\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 16.3559 - mse: 16.3559 - mae: 3.5407\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 14.9110 - mse: 14.9110 - mae: 3.3534\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 13.5650 - mse: 13.5650 - mae: 3.1721\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 12.3352 - mse: 12.3352 - mae: 2.9976\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 998us/step - loss: 11.2368 - mse: 11.2368 - mae: 2.8332\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 10.2445 - mse: 10.2445 - mae: 2.6798\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 9.3750 - mse: 9.3750 - mae: 2.5405\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 962us/step - loss: 8.6185 - mse: 8.6185 - mae: 2.4269\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 7.9840 - mse: 7.9840 - mae: 2.3203\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 986us/step - loss: 7.4348 - mse: 7.4348 - mae: 2.2317\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 901us/step - loss: 6.9814 - mse: 6.9814 - mae: 2.1550\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 6.6000 - mse: 6.6000 - mae: 2.0809\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.2996 - mse: 6.2996 - mae: 2.0237\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0255 - mse: 6.0255 - mae: 1.9757\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 5.7702 - mse: 5.7702 - mae: 1.9317\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 889us/step - loss: 5.5455 - mse: 5.5455 - mae: 1.8919\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 991us/step - loss: 5.3466 - mse: 5.3466 - mae: 1.8587\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 976us/step - loss: 5.1606 - mse: 5.1606 - mae: 1.8271\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 887us/step - loss: 4.9891 - mse: 4.9891 - mae: 1.7926\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 4.8126 - mse: 4.8126 - mae: 1.7600\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.6490 - mse: 4.6490 - mae: 1.7300\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4956 - mse: 4.4956 - mae: 1.7001\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.3491 - mse: 4.3491 - mae: 1.6763\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 875us/step - loss: 4.2179 - mse: 4.2179 - mae: 1.6442\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 984us/step - loss: 4.0908 - mse: 4.0908 - mae: 1.6260\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9848 - mse: 3.9848 - mae: 1.6009\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 869us/step - loss: 3.8731 - mse: 3.8731 - mae: 1.5814\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 889us/step - loss: 3.7736 - mse: 3.7736 - mae: 1.5624\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.6733 - mse: 3.6733 - mae: 1.5364\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.5728 - mse: 3.5728 - mae: 1.5222\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.4813 - mse: 3.4813 - mae: 1.5026\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 3.3894 - mse: 3.3894 - mae: 1.4806\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 3.3116 - mse: 3.3116 - mae: 1.4609\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.2324 - mse: 3.2324 - mae: 1.4461\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 3.1659 - mse: 3.1659 - mae: 1.4247\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 887us/step - loss: 3.0973 - mse: 3.0973 - mae: 1.4103\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 3.0427 - mse: 3.0427 - mae: 1.3945\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.9815 - mse: 2.9815 - mae: 1.3842\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 961us/step - loss: 2.9227 - mse: 2.9227 - mae: 1.3661\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 765us/step - loss: 2.8767 - mse: 2.8767 - mae: 1.3586\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.8172 - mse: 2.8172 - mae: 1.3398\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.7746 - mse: 2.7746 - mae: 1.3280\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 970us/step - loss: 2.7224 - mse: 2.7224 - mae: 1.3090\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 858us/step - loss: 2.6838 - mse: 2.6838 - mae: 1.3023\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.6455 - mse: 2.6455 - mae: 1.2909\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.6016 - mse: 2.6016 - mae: 1.2799\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 989us/step - loss: 2.5751 - mse: 2.5751 - mae: 1.2654\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.5452 - mse: 2.5452 - mae: 1.2552\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 936us/step - loss: 2.5123 - mse: 2.5123 - mae: 1.2451\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4820 - mse: 2.4820 - mae: 1.2348\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 989us/step - loss: 2.4564 - mse: 2.4564 - mae: 1.2299\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.4316 - mse: 2.4316 - mae: 1.2200\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 877us/step - loss: 2.4108 - mse: 2.4108 - mae: 1.2146\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 966us/step - loss: 2.3860 - mse: 2.3860 - mae: 1.2089\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 939us/step - loss: 2.3615 - mse: 2.3615 - mae: 1.2017\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.3391 - mse: 2.3391 - mae: 1.1935\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 944us/step - loss: 2.3255 - mse: 2.3255 - mae: 1.1889\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2928 - mse: 2.2928 - mae: 1.1800\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 966us/step - loss: 2.2750 - mse: 2.2750 - mae: 1.1731\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.2521 - mse: 2.2521 - mae: 1.1617\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2328 - mse: 2.2328 - mae: 1.1563\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2185 - mse: 2.2185 - mae: 1.1530\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.1939 - mse: 2.1939 - mae: 1.1406\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 957us/step - loss: 2.1800 - mse: 2.1800 - mae: 1.1319\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 954us/step - loss: 2.1619 - mse: 2.1619 - mae: 1.1285\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.1488 - mse: 2.1488 - mae: 1.1217\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.1315 - mse: 2.1315 - mae: 1.1189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6507443a0>"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit(train_scal_data,train_target,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9345 - mse: 1.9345 - mae: 1.0514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9345118999481201, 1.9345118999481201, 1.0513694286346436]"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(test_scal_data,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "예측값 : [[13.683215  13.820993   7.5739627  6.469178   6.203334  11.130199\n",
      "  12.539471   5.8466244  8.092578   5.0091305  5.577324  16.830597\n",
      "  12.838512   5.901186  10.405424   6.269112  13.83526    7.3585634\n",
      "   6.4795437 16.793835  10.077336   7.8384385 10.345658  12.232462\n",
      "   6.224945  16.285507  10.283633   9.971308   6.958193   6.795562\n",
      "  12.857387  15.702688   8.791788   9.975055  15.880443   4.8999844\n",
      "   7.64688    6.9573293  6.714348  10.823458   8.798646  13.06334\n",
      "   6.9330363  4.9819956  9.057005  15.34424   10.947279   7.602957\n",
      "   9.513912  11.433354  10.818453  15.43142   14.852113   5.967373\n",
      "  10.232284   6.3450317  8.018989  13.158158  10.11768    6.584319\n",
      "   5.4762383 13.530495   9.802629   8.267734   7.396063  10.0908575\n",
      "  11.02942   15.655163  13.283724   6.5331326 15.243952   6.1417494\n",
      "   5.9345536  6.4873095 10.639227   8.331434   6.977367  13.647814\n",
      "  12.238571   8.288296   5.6502995 10.966907  16.712149  13.898018\n",
      "   8.505678   6.33953   14.107586  14.956001  10.622533   6.2779875\n",
      "   6.314768  15.531599  11.134798  13.830201   5.9121733 15.829519\n",
      "  13.522426   8.189966  10.905516   6.1073904]]\n",
      "실제값 : [[14.0297 11.904   8.0777  5.5269  5.952  11.4789 10.2034  5.5269  7.2274\n",
      "   8.928   6.3772 16.1555 11.0537  6.3772 10.6286  5.1017 13.1795  7.2274\n",
      "   6.8023 13.1795  9.3532  9.3532  9.3532 14.2423  7.6526 18.7063 11.0537\n",
      "  10.416   7.6951  5.1017 11.4789 15.3052  9.7783 10.2034 15.8153  6.8023\n",
      "   8.928   8.1628  6.8023 12.3292 11.3939 11.4789  7.6526  4.2514  9.7783\n",
      "  15.3052 11.0537 10.6286 10.6286 10.6286  9.3532 14.4974 13.7747  5.5269\n",
      "   9.9909  5.952   7.8652 12.6693 11.904   8.0777  4.6766 14.0297  9.7783\n",
      "   8.928   9.7783 10.6286 10.1184 14.6249 10.416   5.5269 14.7525  5.952\n",
      "   6.3772  7.6526 10.6286  8.4604  7.44   11.904  12.3292  7.2274  6.8023\n",
      "  11.4789 15.7303 15.3477  9.7783  5.952  13.9447 12.7118  8.5029  5.1017\n",
      "   6.5897 10.0759 10.2034 15.3052  8.0777 16.1555 12.3292  9.1406 11.8615\n",
      "   5.952 ]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "print(f\"예측값 : {model.predict(test_scal_data).reshape(1,-1)}\")\n",
    "print(f\"실제값 : {np.array(test_target).reshape(1,-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compile 값 변경해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 104.0107 - mse: 104.0107 - mae: 9.6873\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 100.7394 - mse: 100.7394 - mae: 9.5377\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 98.1910 - mse: 98.1910 - mae: 9.4185\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 95.6846 - mse: 95.6846 - mae: 9.3004\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 93.1459 - mse: 93.1459 - mae: 9.1805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e64d115b80>"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential(name='AUTOMPG')\n",
    "l1=Dense(10,activation='relu',input_shape=(7,))\n",
    "l2=Dense(1,activation='linear')\n",
    "model.add(l1)\n",
    "model.add(l2)\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['mse','mae'])\n",
    "model.fit(train_scal_data,train_target,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 998us/step\n",
      "예측값\n",
      "[[1.6247286 ]\n",
      " [1.5030259 ]\n",
      " [0.62091845]\n",
      " [0.37609106]\n",
      " [0.64069945]\n",
      " [1.1624895 ]\n",
      " [1.460915  ]\n",
      " [0.5569942 ]\n",
      " [0.31765354]\n",
      " [0.50862694]\n",
      " [0.65640324]\n",
      " [2.2507827 ]\n",
      " [0.83733314]\n",
      " [0.6733444 ]\n",
      " [0.53320724]\n",
      " [0.69937724]\n",
      " [1.526649  ]\n",
      " [0.6118397 ]\n",
      " [0.4082411 ]\n",
      " [2.2528794 ]\n",
      " [0.52380395]\n",
      " [0.743837  ]\n",
      " [1.0389605 ]\n",
      " [0.9519789 ]\n",
      " [0.7201484 ]\n",
      " [1.9142817 ]\n",
      " [0.6142506 ]\n",
      " [0.6407532 ]\n",
      " [0.33698624]\n",
      " [0.6107475 ]\n",
      " [1.4812548 ]\n",
      " [2.1386518 ]\n",
      " [0.22525865]\n",
      " [1.0969205 ]\n",
      " [1.9751571 ]\n",
      " [0.66613823]\n",
      " [0.5683165 ]\n",
      " [0.39663285]\n",
      " [0.36744016]\n",
      " [0.66174626]\n",
      " [0.5985378 ]\n",
      " [0.92314696]\n",
      " [0.21590818]\n",
      " [0.7474746 ]\n",
      " [0.93897337]\n",
      " [2.3475168 ]\n",
      " [0.70886296]\n",
      " [0.86687696]\n",
      " [0.5290294 ]\n",
      " [0.9350239 ]\n",
      " [0.75084245]\n",
      " [1.9228042 ]\n",
      " [1.8664752 ]\n",
      " [0.61467075]\n",
      " [0.84085554]\n",
      " [0.6600984 ]\n",
      " [0.350003  ]\n",
      " [1.7217962 ]\n",
      " [0.6921886 ]\n",
      " [0.16364405]\n",
      " [0.5634931 ]\n",
      " [1.6158599 ]\n",
      " [0.7989381 ]\n",
      " [0.25169843]\n",
      " [0.5556366 ]\n",
      " [1.1306784 ]\n",
      " [1.0455348 ]\n",
      " [1.5916697 ]\n",
      " [0.9709478 ]\n",
      " [0.6515226 ]\n",
      " [1.5192224 ]\n",
      " [0.61537117]\n",
      " [0.65685946]\n",
      " [0.6050394 ]\n",
      " [0.8748593 ]\n",
      " [0.35128385]\n",
      " [0.24590339]\n",
      " [1.5200492 ]\n",
      " [1.1915367 ]\n",
      " [0.30558312]\n",
      " [0.71440285]\n",
      " [1.1191756 ]\n",
      " [2.2010672 ]\n",
      " [1.6465913 ]\n",
      " [0.7151082 ]\n",
      " [0.6136946 ]\n",
      " [1.4160777 ]\n",
      " [1.4322009 ]\n",
      " [1.0187541 ]\n",
      " [0.58877164]\n",
      " [0.48027587]\n",
      " [2.0997798 ]\n",
      " [0.7750175 ]\n",
      " [1.251645  ]\n",
      " [0.6221707 ]\n",
      " [1.6709353 ]\n",
      " [1.5925685 ]\n",
      " [0.43164712]\n",
      " [1.3384808 ]\n",
      " [0.67464876]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"예측값\\n{model.predict(test_scal_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 1ms/step - loss: 1.7725 - mse: 107.9910 - mae: 9.8056\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0858 - mse: 105.0954 - mae: 9.6917\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7428 - mse: 103.0728 - mae: 9.6099\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5548 - mse: 101.3821 - mae: 9.5371\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4146 - mse: 100.1203 - mae: 9.4802\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3098 - mse: 98.7818 - mae: 9.4179\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2376 - mse: 97.7115 - mae: 9.3653\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1676 - mse: 96.5433 - mae: 9.3084\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1116 - mse: 95.5512 - mae: 9.2604\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0835 - mse: 94.5857 - mae: 9.2136\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 93.9693 - mae: 9.1834\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 93.4058 - mae: 9.1560\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 92.9143 - mae: 9.1301\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0255 - mse: 92.5192 - mae: 9.1075\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0145 - mse: 92.1186 - mae: 9.0859\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0069 - mse: 91.6807 - mae: 9.0634\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0027 - mse: 91.3392 - mae: 9.0475\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.9111e-04 - mse: 91.1236 - mae: 9.0364\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 330/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 331/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 332/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 333/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 334/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 335/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 336/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 337/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 338/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 339/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 340/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 341/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 342/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 343/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 344/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 345/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 346/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 347/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 348/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 349/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 350/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 351/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 352/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 353/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 354/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 355/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 356/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 357/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 358/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 359/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 360/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 361/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 362/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 363/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 364/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 365/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 366/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 367/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 368/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 369/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 370/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 371/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 372/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 373/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 374/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 375/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 376/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 377/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 378/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 379/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 380/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 381/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 382/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 383/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 384/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 385/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 386/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 387/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 388/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 389/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 390/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 391/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 392/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 393/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 394/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 395/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 396/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 397/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 398/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 399/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 400/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 401/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 402/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 403/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 404/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 405/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 406/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 407/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 408/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 409/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 410/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 411/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 412/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 413/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 414/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 415/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 416/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 417/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 418/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 419/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 420/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 421/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 422/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 423/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 424/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 425/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 426/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 427/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 428/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 429/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 430/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 431/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 432/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 433/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 434/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 435/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 436/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 437/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 438/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 439/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 440/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 441/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 442/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 443/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 444/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 445/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 446/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 447/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 448/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 449/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 450/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 451/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 452/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 453/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 454/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 455/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 456/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 457/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 458/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 459/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 460/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 461/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 462/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 463/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 464/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 465/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 466/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 467/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 468/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 469/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 470/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 471/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 472/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 473/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 474/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 475/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 476/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 477/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 478/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 479/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 480/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 481/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 482/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 483/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 484/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 485/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 486/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 487/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 488/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 489/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 490/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 491/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 492/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 493/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 494/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 495/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 496/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 497/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 498/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 499/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 500/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 501/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 502/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 503/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 504/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 505/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 506/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 507/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 508/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 509/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 510/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 511/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 512/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 513/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 514/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 515/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 516/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 517/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 518/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 519/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 520/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 521/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 522/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 523/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 524/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 525/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 526/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 527/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 528/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 529/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 530/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 531/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 532/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 533/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 534/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 535/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 536/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 537/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 538/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 539/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 540/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 541/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 542/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 543/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 544/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 545/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 546/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 547/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 548/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 549/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 550/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 551/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 552/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 553/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 554/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 555/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 556/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 557/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 558/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 559/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 560/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 561/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 562/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 563/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 564/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 565/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 566/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 567/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 568/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 569/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 570/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 571/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 572/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 573/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 574/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 575/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 576/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 577/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 578/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 579/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 580/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 581/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 582/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 583/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 584/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 585/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 586/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 587/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 588/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 589/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 590/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 591/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 592/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 593/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 594/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 595/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 596/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 597/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 598/1000\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 599/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 600/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 601/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 602/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 603/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 604/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 605/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 606/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 607/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 608/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 609/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 610/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 611/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 612/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 613/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 614/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 615/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 616/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 617/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 618/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 619/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 620/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 621/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 622/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 623/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 624/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 625/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 626/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 627/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 628/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 629/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 630/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 631/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 632/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 633/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 634/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 635/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 636/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 637/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 638/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 639/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 640/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 641/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 642/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 643/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 644/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 645/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 646/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 647/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 648/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 649/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 650/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 651/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 652/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 653/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 654/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 655/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 656/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 657/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 658/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 659/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 660/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 661/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 662/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 663/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 664/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 665/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 666/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 667/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 668/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 669/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 670/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 671/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 672/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 673/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 674/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 675/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 676/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 677/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 678/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 679/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 680/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 681/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 682/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 683/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 684/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 685/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 686/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 687/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 688/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 689/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 690/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 691/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 692/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 693/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 694/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 695/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 696/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 697/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 698/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 699/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 700/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 701/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 702/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 703/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 704/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 705/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 706/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 707/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 708/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 709/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 710/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 711/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 712/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 713/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 714/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 715/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 716/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 717/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 718/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 719/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 720/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 721/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 722/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 723/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 724/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 725/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 726/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 727/1000\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 728/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 729/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 730/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 731/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 732/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 733/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 734/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 735/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 736/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 737/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 738/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 739/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 740/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 741/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 742/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 743/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 744/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 745/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 746/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 747/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 748/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 749/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 750/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 751/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 752/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 753/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 754/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 755/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 756/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 757/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 758/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 759/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 760/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 761/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 762/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 763/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 764/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 765/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 766/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 767/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 768/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 769/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 770/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 771/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 772/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 773/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 774/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 775/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 776/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 777/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 778/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 779/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 780/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 781/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 782/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 783/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 784/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 785/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 786/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 787/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 788/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 789/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 790/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 791/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 792/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 793/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 794/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 795/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 796/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 797/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 798/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 799/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 800/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 801/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 802/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 803/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 804/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 805/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 806/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 807/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 808/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 809/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 810/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 811/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 812/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 813/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 814/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 815/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 816/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 817/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 818/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 819/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 820/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 821/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 822/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 823/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 824/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 825/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 826/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 827/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 828/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 829/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 830/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 831/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 832/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 833/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 834/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 835/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 836/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 837/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 838/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 839/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 840/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 841/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 842/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 843/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 844/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 845/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 846/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 847/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 848/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 849/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 850/1000\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 851/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 852/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 853/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 854/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 855/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 856/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 857/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 858/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 859/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 860/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 861/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 862/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 863/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 864/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 865/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 866/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 867/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 868/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 869/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 870/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 871/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 872/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 873/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 874/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 875/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 876/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 877/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 878/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 879/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 880/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 881/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 882/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 883/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 884/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 885/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 886/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 887/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 888/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 889/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 890/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 891/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 892/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 893/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 894/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 895/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 896/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 897/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 898/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 899/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 900/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 901/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 902/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 903/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 904/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 905/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 906/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 907/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 908/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 909/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 910/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 911/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 912/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 913/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 914/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 915/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 916/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 917/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 918/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 919/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 920/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 921/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 922/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 923/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 924/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 925/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 926/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 927/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 928/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 929/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 930/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 931/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 932/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 933/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 934/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 935/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 936/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 937/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 938/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 939/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 940/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 941/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 942/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 943/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 944/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 945/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 946/1000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 947/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 948/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 949/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 950/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 951/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 952/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 953/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 954/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 955/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 956/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 957/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 958/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 959/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 960/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 961/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 962/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 963/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 964/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 965/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 966/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 967/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 968/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 969/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 970/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 971/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 972/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 973/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 974/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 975/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 976/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 977/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 978/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 979/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 980/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 981/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 982/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 983/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 984/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 985/1000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 986/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 987/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 988/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 989/1000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 990/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 991/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 992/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 993/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 994/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 995/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 996/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 997/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 998/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9484 - mae: 9.0275\n",
      "Epoch 999/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n",
      "Epoch 1000/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 90.9485 - mae: 9.0275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e64d241070>"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential(name='AUTOMPG')\n",
    "l1=Dense(10,activation='relu',input_shape=(7,))\n",
    "l2=Dense(1,activation='linear')\n",
    "model.add(l1)\n",
    "model.add(l2)\n",
    "model.compile(optimizer='rmsprop',loss='hinge',metrics=['mse','mae'])\n",
    "model.fit(train_scal_data,train_target,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "예측값\n",
      "[[1.5914344 ]\n",
      " [1.7784706 ]\n",
      " [0.15642852]\n",
      " [0.75334394]\n",
      " [0.92837095]\n",
      " [0.83226997]\n",
      " [1.4495687 ]\n",
      " [0.79774743]\n",
      " [0.8071778 ]\n",
      " [0.16095033]\n",
      " [0.540548  ]\n",
      " [1.0507052 ]\n",
      " [1.5621142 ]\n",
      " [0.7636547 ]\n",
      " [0.89371824]\n",
      " [0.9971377 ]\n",
      " [1.8217217 ]\n",
      " [0.4098003 ]\n",
      " [0.7602433 ]\n",
      " [1.0321292 ]\n",
      " [0.847005  ]\n",
      " [0.12901793]\n",
      " [0.3015035 ]\n",
      " [1.6896927 ]\n",
      " [0.7350762 ]\n",
      " [1.5314727 ]\n",
      " [0.7187613 ]\n",
      " [1.3072727 ]\n",
      " [0.27088708]\n",
      " [1.1439385 ]\n",
      " [1.5209882 ]\n",
      " [1.3382876 ]\n",
      " [0.4569263 ]\n",
      " [0.79383826]\n",
      " [1.5044878 ]\n",
      " [0.52593213]\n",
      " [0.1499301 ]\n",
      " [0.5704576 ]\n",
      " [0.9349818 ]\n",
      " [0.7110364 ]\n",
      " [1.164075  ]\n",
      " [1.2830436 ]\n",
      " [0.3903157 ]\n",
      " [0.60594016]\n",
      " [0.852049  ]\n",
      " [0.56668544]\n",
      " [0.7126137 ]\n",
      " [0.9078388 ]\n",
      " [0.8652092 ]\n",
      " [1.6393316 ]\n",
      " [1.2197074 ]\n",
      " [1.6767248 ]\n",
      " [1.2647591 ]\n",
      " [0.7745504 ]\n",
      " [0.9745125 ]\n",
      " [0.8657428 ]\n",
      " [0.48303688]\n",
      " [0.8024653 ]\n",
      " [1.0406635 ]\n",
      " [0.44424337]\n",
      " [0.5393886 ]\n",
      " [1.7258075 ]\n",
      " [1.5850754 ]\n",
      " [0.6783307 ]\n",
      " [0.2321437 ]\n",
      " [0.83312565]\n",
      " [1.925836  ]\n",
      " [2.3694    ]\n",
      " [2.0632226 ]\n",
      " [0.964303  ]\n",
      " [2.257166  ]\n",
      " [0.9584994 ]\n",
      " [0.68656003]\n",
      " [0.20459458]\n",
      " [0.5844948 ]\n",
      " [0.7219648 ]\n",
      " [0.32135212]\n",
      " [1.7956854 ]\n",
      " [1.6900352 ]\n",
      " [0.45580304]\n",
      " [0.57046914]\n",
      " [0.9597767 ]\n",
      " [1.0233648 ]\n",
      " [1.1720902 ]\n",
      " [1.1759925 ]\n",
      " [0.861142  ]\n",
      " [1.3332515 ]\n",
      " [2.2043707 ]\n",
      " [0.84153825]\n",
      " [0.97799945]\n",
      " [0.73891175]\n",
      " [1.0474153 ]\n",
      " [0.809333  ]\n",
      " [1.6977434 ]\n",
      " [0.751495  ]\n",
      " [2.16195   ]\n",
      " [1.7205485 ]\n",
      " [0.4353063 ]\n",
      " [1.6773703 ]\n",
      " [0.83779764]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"예측값\\n{model.predict(test_scal_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3087 - mse: 116.4447 - mae: 10.1475\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1678 - mse: 114.3688 - mae: 10.0348\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1074 - mse: 113.4253 - mae: 9.9876\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0134 - mse: 111.9792 - mae: 9.9256\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.2349 - mse: 110.4552 - mae: 9.8522\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.2081 - mse: 110.6801 - mae: 9.8603\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.1275 - mse: 111.6461 - mae: 9.8976\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.1879 - mse: 110.3048 - mae: 9.8361\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.2886 - mse: 109.4945 - mae: 9.7975\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.3826 - mse: 108.5676 - mae: 9.7516\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.5436 - mse: 106.8884 - mae: 9.6674\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.5772 - mse: 106.3352 - mae: 9.6403\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.7114 - mse: 104.6223 - mae: 9.5670\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.7248 - mse: 104.1997 - mae: 9.5467\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.7584 - mse: 103.4978 - mae: 9.5129\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.7785 - mse: 102.5994 - mae: 9.4657\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.8389 - mse: 101.2430 - mae: 9.3965\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.8859 - mse: 100.0403 - mae: 9.3355\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.8725 - mse: 99.7445 - mae: 9.3277\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.8725 - mse: 99.3887 - mae: 9.3075\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9195 - mse: 98.3806 - mae: 9.2586\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9597 - mse: 97.1595 - mae: 9.1979\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9732 - mse: 96.4138 - mae: 9.1592\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.9866 - mse: 95.5260 - mae: 9.1133\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9866 - mse: 94.5850 - mae: 9.0636\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.9933 - mse: 94.0656 - mae: 9.0336\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9866 - mse: 93.9017 - mae: 9.0209\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9866 - mse: 93.1501 - mae: 8.9822\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9933 - mse: 92.5198 - mae: 8.9490\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9933 - mse: 91.8369 - mae: 8.9137\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9933 - mse: 91.1295 - mae: 8.8764\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.9933 - mse: 90.4433 - mae: 8.8405\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.9933 - mse: 89.8019 - mae: 8.8038\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 89.0234 - mae: 8.7605\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 88.3251 - mae: 8.7207\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 87.5588 - mae: 8.6766\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 86.9243 - mae: 8.6393\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 86.1843 - mae: 8.5963\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 85.6724 - mae: 8.5673\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 85.1219 - mae: 8.5358\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 84.5374 - mae: 8.5022\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 84.1080 - mae: 8.4767\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 83.7970 - mae: 8.4576\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 83.3824 - mae: 8.4327\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 82.9225 - mae: 8.4069\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 82.5724 - mae: 8.3872\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 968us/step - loss: -1.0000 - mse: 82.1623 - mae: 8.3647\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 81.7194 - mae: 8.3389\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 81.3352 - mae: 8.3156\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 80.8066 - mae: 8.2848\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 80.2198 - mae: 8.2505\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 987us/step - loss: -1.0000 - mse: 79.7579 - mae: 8.2248\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 79.3421 - mae: 8.2002\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 78.7933 - mae: 8.1693\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 78.2223 - mae: 8.1364\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 77.8073 - mae: 8.1126\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 77.4078 - mae: 8.0868\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 76.9963 - mae: 8.0625\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 76.5134 - mae: 8.0329\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 76.0447 - mae: 8.0043\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 75.6257 - mae: 7.9784\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 75.2470 - mae: 7.9535\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 74.8124 - mae: 7.9260\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 74.3288 - mae: 7.8957\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 73.9114 - mae: 7.8692\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 73.4205 - mae: 7.8388\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 73.1237 - mae: 7.8196\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 72.8383 - mae: 7.8002\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 72.4273 - mae: 7.7728\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 1000us/step - loss: -1.0000 - mse: 72.0454 - mae: 7.7476\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 71.6848 - mae: 7.7229\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 71.2891 - mae: 7.6964\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 70.8493 - mae: 7.6688\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 70.4059 - mae: 7.6403\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 70.0640 - mae: 7.6177\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 69.6550 - mae: 7.5917\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 69.2367 - mae: 7.5653\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 68.8588 - mae: 7.5421\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 68.4616 - mae: 7.5173\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 68.1446 - mae: 7.4975\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 67.8394 - mae: 7.4765\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 67.4611 - mae: 7.4525\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 67.1281 - mae: 7.4311\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 66.8037 - mae: 7.4095\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 66.4999 - mae: 7.3901\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 66.1872 - mae: 7.3692\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 65.8375 - mae: 7.3450\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 65.5005 - mae: 7.3233\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 65.1643 - mae: 7.3001\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 64.8523 - mae: 7.2785\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 64.5474 - mae: 7.2569\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 64.2796 - mae: 7.2376\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 64.0154 - mae: 7.2202\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 63.7006 - mae: 7.1995\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 63.4370 - mae: 7.1803\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 63.1197 - mae: 7.1586\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 62.8390 - mae: 7.1396\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 62.5452 - mae: 7.1196\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 62.2619 - mae: 7.0994\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 61.9995 - mae: 7.0795\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 61.7503 - mae: 7.0615\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 61.5605 - mae: 7.0474\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 61.2549 - mae: 7.0268\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 60.9781 - mae: 7.0066\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 60.7116 - mae: 6.9885\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 60.4717 - mae: 6.9713\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 60.2215 - mae: 6.9529\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 59.9209 - mae: 6.9300\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 59.6194 - mae: 6.9087\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 59.3333 - mae: 6.8864\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 59.0333 - mae: 6.8646\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 58.6768 - mae: 6.8388\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 58.3758 - mae: 6.8173\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 58.0528 - mae: 6.7934\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 57.7814 - mae: 6.7724\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 57.3916 - mae: 6.7436\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 57.0978 - mae: 6.7217\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 56.8584 - mae: 6.7030\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 56.5053 - mae: 6.6777\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 56.2558 - mae: 6.6596\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 55.9777 - mae: 6.6387\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 55.6376 - mae: 6.6138\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 55.2655 - mae: 6.5865\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 54.9305 - mae: 6.5625\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 54.6918 - mae: 6.5445\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 54.3314 - mae: 6.5188\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 54.0756 - mae: 6.4998\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 53.8047 - mae: 6.4805\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 53.5065 - mae: 6.4597\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 53.2168 - mae: 6.4385\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 52.9601 - mae: 6.4198\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 52.7306 - mae: 6.4023\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 52.4442 - mae: 6.3805\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 52.1890 - mae: 6.3616\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 51.8970 - mae: 6.3400\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 51.6509 - mae: 6.3203\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 51.4062 - mae: 6.3017\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 917us/step - loss: -1.0000 - mse: 51.0691 - mae: 6.2767\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 50.7924 - mae: 6.2565\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 50.5498 - mae: 6.2394\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 999us/step - loss: -1.0000 - mse: 50.2791 - mae: 6.2199\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 50.0373 - mae: 6.2016\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 49.7471 - mae: 6.1791\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 49.4969 - mae: 6.1602\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 997us/step - loss: -1.0000 - mse: 49.2114 - mae: 6.1369\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 48.9402 - mae: 6.1160\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 48.6236 - mae: 6.0925\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 48.3310 - mae: 6.0704\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 48.1083 - mae: 6.0522\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 47.8084 - mae: 6.0298\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 47.5304 - mae: 6.0083\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 47.2750 - mae: 5.9891\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 46.9857 - mae: 5.9669\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 46.7213 - mae: 5.9468\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 46.4755 - mae: 5.9276\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 46.2387 - mae: 5.9088\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 46.0157 - mae: 5.8919\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 45.8043 - mae: 5.8746\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 45.6223 - mae: 5.8601\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 45.4476 - mae: 5.8456\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 45.2443 - mae: 5.8299\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 45.0047 - mae: 5.8109\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 44.7785 - mae: 5.7921\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 44.5560 - mae: 5.7744\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 998us/step - loss: -1.0000 - mse: 44.3183 - mae: 5.7550\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 44.1070 - mae: 5.7378\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 43.8861 - mae: 5.7197\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 43.6306 - mae: 5.6993\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 43.4326 - mae: 5.6827\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 43.1955 - mae: 5.6639\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 42.9192 - mae: 5.6416\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 42.6557 - mae: 5.6205\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 42.4357 - mae: 5.6038\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 42.2503 - mae: 5.5900\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 42.0547 - mae: 5.5742\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 41.8569 - mae: 5.5596\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 41.6507 - mae: 5.5438\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 41.3827 - mae: 5.5237\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: -1.0000 - mse: 41.1534 - mae: 5.5061\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 40.8786 - mae: 5.4856\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 40.6839 - mae: 5.4707\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 40.4478 - mae: 5.4524\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: -1.0000 - mse: 40.2505 - mae: 5.4373\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 40.0227 - mae: 5.4196\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 39.7888 - mae: 5.4022\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 39.5828 - mae: 5.3867\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 39.4225 - mae: 5.3740\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 39.1890 - mae: 5.3563\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 38.9776 - mae: 5.3401\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 38.7160 - mae: 5.3203\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 38.5218 - mae: 5.3060\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 38.3195 - mae: 5.2912\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 38.1235 - mae: 5.2768\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 37.8890 - mae: 5.2593\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 37.6914 - mae: 5.2445\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 37.5261 - mae: 5.2322\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 37.3499 - mae: 5.2193\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 37.1488 - mae: 5.2043\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 36.9555 - mae: 5.1897\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 36.7235 - mae: 5.1727\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "예측값\n",
      "[[6.8686814]\n",
      " [4.4638777]\n",
      " [4.9550405]\n",
      " [5.3255424]\n",
      " [6.085401 ]\n",
      " [5.668242 ]\n",
      " [4.0312767]\n",
      " [6.593784 ]\n",
      " [4.9000173]\n",
      " [4.6339984]\n",
      " [6.388484 ]\n",
      " [6.610959 ]\n",
      " [6.1265492]\n",
      " [6.0570498]\n",
      " [5.305232 ]\n",
      " [6.570571 ]\n",
      " [4.432556 ]\n",
      " [2.5904129]\n",
      " [5.588001 ]\n",
      " [6.5829773]\n",
      " [5.455012 ]\n",
      " [5.311676 ]\n",
      " [3.045515 ]\n",
      " [4.6845007]\n",
      " [5.9847245]\n",
      " [5.9675217]\n",
      " [5.4256506]\n",
      " [3.6757493]\n",
      " [3.4259942]\n",
      " [6.4668775]\n",
      " [4.193058 ]\n",
      " [5.7641945]\n",
      " [4.1173058]\n",
      " [5.223814 ]\n",
      " [6.314328 ]\n",
      " [6.436805 ]\n",
      " [4.786808 ]\n",
      " [4.7366905]\n",
      " [5.6246533]\n",
      " [5.5666227]\n",
      " [2.460976 ]\n",
      " [6.2846994]\n",
      " [4.4397483]\n",
      " [6.485544 ]\n",
      " [5.0796175]\n",
      " [5.89804  ]\n",
      " [5.593693 ]\n",
      " [3.143228 ]\n",
      " [5.3646045]\n",
      " [5.3661513]\n",
      " [5.4854107]\n",
      " [6.1943445]\n",
      " [5.856831 ]\n",
      " [6.4659796]\n",
      " [3.0902343]\n",
      " [6.474911 ]\n",
      " [4.2915416]\n",
      " [5.004381 ]\n",
      " [5.2794666]\n",
      " [3.7223227]\n",
      " [6.0644627]\n",
      " [6.7261095]\n",
      " [3.9814746]\n",
      " [4.813841 ]\n",
      " [4.6777096]\n",
      " [5.151416 ]\n",
      " [3.109403 ]\n",
      " [5.116475 ]\n",
      " [5.207865 ]\n",
      " [6.106835 ]\n",
      " [4.9735603]\n",
      " [5.95848  ]\n",
      " [6.6161036]\n",
      " [4.942221 ]\n",
      " [3.0838902]\n",
      " [4.3963985]\n",
      " [3.5766072]\n",
      " [4.3637404]\n",
      " [5.653063 ]\n",
      " [3.9922624]\n",
      " [6.045849 ]\n",
      " [5.3775806]\n",
      " [6.523365 ]\n",
      " [6.8575964]\n",
      " [4.0084343]\n",
      " [6.414772 ]\n",
      " [6.9722705]\n",
      " [4.7781672]\n",
      " [5.657734 ]\n",
      " [6.5785894]\n",
      " [5.662058 ]\n",
      " [5.239081 ]\n",
      " [5.6984425]\n",
      " [6.291629 ]\n",
      " [4.1044545]\n",
      " [5.225684 ]\n",
      " [4.46739  ]\n",
      " [2.6224532]\n",
      " [3.3671308]\n",
      " [6.1310234]]\n"
     ]
    }
   ],
   "source": [
    "model=Sequential(name='AUTOMPG')\n",
    "l1=Dense(10,activation='relu',input_shape=(7,))\n",
    "l2=Dense(20,activation='selu')\n",
    "l3=Dense(1,activation='linear')\n",
    "model.add(l1)\n",
    "model.add(l2)\n",
    "model.add(l3)\n",
    "model.compile(optimizer='rmsprop',loss='cosine_similarity',metrics=['mse','mae'])\n",
    "model.fit(train_scal_data,train_target,epochs=200)\n",
    "\n",
    "print(f\"예측값\\n{model.predict(test_scal_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 998us/step\n",
      "예측값\n",
      "[[6.8686814]\n",
      " [4.4638777]\n",
      " [4.9550405]\n",
      " [5.3255424]\n",
      " [6.085401 ]\n",
      " [5.668242 ]\n",
      " [4.0312767]\n",
      " [6.593784 ]\n",
      " [4.9000173]\n",
      " [4.6339984]\n",
      " [6.388484 ]\n",
      " [6.610959 ]\n",
      " [6.1265492]\n",
      " [6.0570498]\n",
      " [5.305232 ]\n",
      " [6.570571 ]\n",
      " [4.432556 ]\n",
      " [2.5904129]\n",
      " [5.588001 ]\n",
      " [6.5829773]\n",
      " [5.455012 ]\n",
      " [5.311676 ]\n",
      " [3.045515 ]\n",
      " [4.6845007]\n",
      " [5.9847245]\n",
      " [5.9675217]\n",
      " [5.4256506]\n",
      " [3.6757493]\n",
      " [3.4259942]\n",
      " [6.4668775]\n",
      " [4.193058 ]\n",
      " [5.7641945]\n",
      " [4.1173058]\n",
      " [5.223814 ]\n",
      " [6.314328 ]\n",
      " [6.436805 ]\n",
      " [4.786808 ]\n",
      " [4.7366905]\n",
      " [5.6246533]\n",
      " [5.5666227]\n",
      " [2.460976 ]\n",
      " [6.2846994]\n",
      " [4.4397483]\n",
      " [6.485544 ]\n",
      " [5.0796175]\n",
      " [5.89804  ]\n",
      " [5.593693 ]\n",
      " [3.143228 ]\n",
      " [5.3646045]\n",
      " [5.3661513]\n",
      " [5.4854107]\n",
      " [6.1943445]\n",
      " [5.856831 ]\n",
      " [6.4659796]\n",
      " [3.0902343]\n",
      " [6.474911 ]\n",
      " [4.2915416]\n",
      " [5.004381 ]\n",
      " [5.2794666]\n",
      " [3.7223227]\n",
      " [6.0644627]\n",
      " [6.7261095]\n",
      " [3.9814746]\n",
      " [4.813841 ]\n",
      " [4.6777096]\n",
      " [5.151416 ]\n",
      " [3.109403 ]\n",
      " [5.116475 ]\n",
      " [5.207865 ]\n",
      " [6.106835 ]\n",
      " [4.9735603]\n",
      " [5.95848  ]\n",
      " [6.6161036]\n",
      " [4.942221 ]\n",
      " [3.0838902]\n",
      " [4.3963985]\n",
      " [3.5766072]\n",
      " [4.3637404]\n",
      " [5.653063 ]\n",
      " [3.9922624]\n",
      " [6.045849 ]\n",
      " [5.3775806]\n",
      " [6.523365 ]\n",
      " [6.8575964]\n",
      " [4.0084343]\n",
      " [6.414772 ]\n",
      " [6.9722705]\n",
      " [4.7781672]\n",
      " [5.657734 ]\n",
      " [6.5785894]\n",
      " [5.662058 ]\n",
      " [5.239081 ]\n",
      " [5.6984425]\n",
      " [6.291629 ]\n",
      " [4.1044545]\n",
      " [5.225684 ]\n",
      " [4.46739  ]\n",
      " [2.6224532]\n",
      " [3.3671308]\n",
      " [6.1310234]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"예측값\\n{model.predict(test_scal_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "10/10 [==============================] - 1s 1ms/step - loss: -0.1879 - mse: 109.8824 - mae: 10.1148 - cosine_similarity: 0.1879\n",
      "Epoch 2/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -0.2886 - mse: 107.4483 - mae: 9.9924 - cosine_similarity: 0.2886\n",
      "Epoch 3/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.3826 - mse: 104.0650 - mae: 9.8137 - cosine_similarity: 0.3826\n",
      "Epoch 4/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.4362 - mse: 101.8780 - mae: 9.6996 - cosine_similarity: 0.4362\n",
      "Epoch 5/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.4362 - mse: 101.2898 - mae: 9.6674 - cosine_similarity: 0.4362\n",
      "Epoch 6/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.4362 - mse: 100.6052 - mae: 9.6288 - cosine_similarity: 0.4362\n",
      "Epoch 7/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.4899 - mse: 98.8694 - mae: 9.5267 - cosine_similarity: 0.4899\n",
      "Epoch 8/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.5436 - mse: 97.1385 - mae: 9.4220 - cosine_similarity: 0.5436\n",
      "Epoch 9/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.5839 - mse: 96.2307 - mae: 9.3669 - cosine_similarity: 0.5839\n",
      "Epoch 10/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.6711 - mse: 95.1362 - mae: 9.2989 - cosine_similarity: 0.6711\n",
      "Epoch 11/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -0.8591 - mse: 93.4101 - mae: 9.1888 - cosine_similarity: 0.8591\n",
      "Epoch 12/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 91.4078 - mae: 9.0527 - cosine_similarity: 1.0000\n",
      "Epoch 13/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 90.8887 - mae: 9.0244 - cosine_similarity: 1.0000\n",
      "Epoch 14/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 90.3690 - mae: 8.9941 - cosine_similarity: 1.0000\n",
      "Epoch 15/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 89.7073 - mae: 8.9550 - cosine_similarity: 1.0000\n",
      "Epoch 16/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 89.1496 - mae: 8.9223 - cosine_similarity: 1.0000\n",
      "Epoch 17/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 88.2724 - mae: 8.8683 - cosine_similarity: 1.0000\n",
      "Epoch 18/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 87.3981 - mae: 8.8136 - cosine_similarity: 1.0000\n",
      "Epoch 19/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 86.5927 - mae: 8.7657 - cosine_similarity: 1.0000\n",
      "Epoch 20/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 85.7604 - mae: 8.7121 - cosine_similarity: 1.0000\n",
      "Epoch 21/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 84.9143 - mae: 8.6608 - cosine_similarity: 1.0000\n",
      "Epoch 22/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 84.1025 - mae: 8.6115 - cosine_similarity: 1.0000\n",
      "Epoch 23/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 83.4919 - mae: 8.5738 - cosine_similarity: 1.0000\n",
      "Epoch 24/70\n",
      "10/10 [==============================] - 0s 3ms/step - loss: -1.0000 - mse: 82.9037 - mae: 8.5365 - cosine_similarity: 1.0000\n",
      "Epoch 25/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 82.2692 - mae: 8.4977 - cosine_similarity: 1.0000\n",
      "Epoch 26/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 81.7449 - mae: 8.4623 - cosine_similarity: 1.0000\n",
      "Epoch 27/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 81.1861 - mae: 8.4278 - cosine_similarity: 1.0000\n",
      "Epoch 28/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 80.6441 - mae: 8.3936 - cosine_similarity: 1.0000\n",
      "Epoch 29/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 80.0341 - mae: 8.3556 - cosine_similarity: 1.0000\n",
      "Epoch 30/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 79.5269 - mae: 8.3233 - cosine_similarity: 1.0000\n",
      "Epoch 31/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 79.0532 - mae: 8.2940 - cosine_similarity: 1.0000\n",
      "Epoch 32/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 78.4100 - mae: 8.2547 - cosine_similarity: 1.0000\n",
      "Epoch 33/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 77.8726 - mae: 8.2218 - cosine_similarity: 1.0000\n",
      "Epoch 34/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 77.3084 - mae: 8.1878 - cosine_similarity: 1.0000\n",
      "Epoch 35/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 76.7810 - mae: 8.1528 - cosine_similarity: 1.0000\n",
      "Epoch 36/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 76.2112 - mae: 8.1159 - cosine_similarity: 1.0000\n",
      "Epoch 37/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 75.6136 - mae: 8.0773 - cosine_similarity: 1.0000\n",
      "Epoch 38/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 75.0979 - mae: 8.0442 - cosine_similarity: 1.0000\n",
      "Epoch 39/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 74.6011 - mae: 8.0130 - cosine_similarity: 1.0000\n",
      "Epoch 40/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 74.1701 - mae: 7.9840 - cosine_similarity: 1.0000\n",
      "Epoch 41/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 73.7345 - mae: 7.9557 - cosine_similarity: 1.0000\n",
      "Epoch 42/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 73.3273 - mae: 7.9297 - cosine_similarity: 1.0000\n",
      "Epoch 43/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 72.7733 - mae: 7.8931 - cosine_similarity: 1.0000\n",
      "Epoch 44/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 72.3416 - mae: 7.8625 - cosine_similarity: 1.0000\n",
      "Epoch 45/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 71.8044 - mae: 7.8265 - cosine_similarity: 1.0000\n",
      "Epoch 46/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 71.2946 - mae: 7.7920 - cosine_similarity: 1.0000\n",
      "Epoch 47/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 70.7704 - mae: 7.7569 - cosine_similarity: 1.0000\n",
      "Epoch 48/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 70.2386 - mae: 7.7200 - cosine_similarity: 1.0000\n",
      "Epoch 49/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 69.7009 - mae: 7.6818 - cosine_similarity: 1.0000\n",
      "Epoch 50/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 69.2053 - mae: 7.6500 - cosine_similarity: 1.0000\n",
      "Epoch 51/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 68.6963 - mae: 7.6156 - cosine_similarity: 1.0000\n",
      "Epoch 52/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 68.3298 - mae: 7.5905 - cosine_similarity: 1.0000\n",
      "Epoch 53/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 67.9287 - mae: 7.5623 - cosine_similarity: 1.0000\n",
      "Epoch 54/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 67.5375 - mae: 7.5339 - cosine_similarity: 1.0000\n",
      "Epoch 55/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 67.1172 - mae: 7.5038 - cosine_similarity: 1.0000\n",
      "Epoch 56/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 66.6600 - mae: 7.4712 - cosine_similarity: 1.0000\n",
      "Epoch 57/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 66.3442 - mae: 7.4487 - cosine_similarity: 1.0000\n",
      "Epoch 58/70\n",
      "10/10 [==============================] - 0s 3ms/step - loss: -1.0000 - mse: 65.9758 - mae: 7.4227 - cosine_similarity: 1.0000\n",
      "Epoch 59/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 65.5667 - mae: 7.3940 - cosine_similarity: 1.0000\n",
      "Epoch 60/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 65.1170 - mae: 7.3634 - cosine_similarity: 1.0000\n",
      "Epoch 61/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 64.7028 - mae: 7.3349 - cosine_similarity: 1.0000\n",
      "Epoch 62/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 64.2771 - mae: 7.3044 - cosine_similarity: 1.0000\n",
      "Epoch 63/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 63.8319 - mae: 7.2728 - cosine_similarity: 1.0000\n",
      "Epoch 64/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 63.5222 - mae: 7.2503 - cosine_similarity: 1.0000\n",
      "Epoch 65/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 63.1490 - mae: 7.2227 - cosine_similarity: 1.0000\n",
      "Epoch 66/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 62.7667 - mae: 7.1939 - cosine_similarity: 1.0000\n",
      "Epoch 67/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 62.4035 - mae: 7.1670 - cosine_similarity: 1.0000\n",
      "Epoch 68/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 62.0400 - mae: 7.1407 - cosine_similarity: 1.0000\n",
      "Epoch 69/70\n",
      "10/10 [==============================] - 0s 2ms/step - loss: -1.0000 - mse: 61.6990 - mae: 7.1150 - cosine_similarity: 1.0000\n",
      "Epoch 70/70\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -1.0000 - mse: 61.3166 - mae: 7.0866 - cosine_similarity: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e64f5a31f0>"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential(name='AUTOMPG')\n",
    "l1=Dense(20,activation='relu',input_shape=(7,))\n",
    "l2=Dense(30,activation='selu')\n",
    "l3=Dense(1,activation='linear')\n",
    "model.add(l1)\n",
    "model.add(l2)\n",
    "model.add(l3)\n",
    "model.compile(optimizer='rmsprop',loss='cosine_similarity',metrics=['mse','mae','cosine_similarity'])\n",
    "model.fit(train_scal_data,train_target,epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.56320571e-01, -9.83551906e-01, -1.33723300e+00,\n",
       "        -1.38975685e+00,  7.52353658e-02, -2.72144865e-03,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -7.05077311e-01, -6.59240707e-01,\n",
       "        -4.08410873e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01,  3.70410780e-01, -1.11631549e-01,\n",
       "        -3.97769846e-01, -1.12251166e+00, -1.35664215e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.19623199e+00,  1.19219978e+00,\n",
       "         1.14637210e+00,  7.52353658e-02, -2.72144865e-03,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.19623199e+00,  1.19219978e+00,\n",
       "         1.49752833e+00, -1.12251166e+00, -8.15073870e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.25936473e-01, -4.24551067e-01,\n",
       "        -1.02914170e+00, -1.12251166e+00, -1.08585801e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -5.13025867e-01, -3.20244561e-01,\n",
       "        -1.24648159e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  2.36774581e+00,  2.88718051e+00,\n",
       "         2.08633581e+00, -1.12251166e+00, -8.15073870e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  6.39282803e-01,  1.49134717e-01,\n",
       "         1.28825332e+00,  7.52353658e-02,  2.68062692e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01,  6.31284680e-02,  9.31433514e-01,\n",
       "        -1.12824767e-01, -1.12251166e+00, -5.44289730e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.88761719e+00,  2.23526484e+00,\n",
       "         1.03996105e+00, -1.12251166e+00, -1.62742629e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.83551906e-01, -9.72160225e-01,\n",
       "        -1.18875814e+00,  1.27298239e+00,  1.62198339e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -9.83551906e-01, -8.93930346e-01,\n",
       "        -1.20058153e+00, -1.12251166e+00, -1.35664215e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.06179598e+00,  1.19219978e+00,\n",
       "         1.08961961e+00, -1.12251166e+00, -1.08585801e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -5.13025867e-01, -7.63547213e-01,\n",
       "        -5.06545366e-01, -1.12251166e+00, -5.44289730e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.82039919e+00,  1.97449858e+00,\n",
       "         2.34645174e+00, -1.12251166e+00, -1.35664215e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -7.81897889e-01, -5.02780947e-01,\n",
       "        -4.67528094e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01, -2.92166705e-01,  5.40284116e-01,\n",
       "         2.00496558e-01,  1.27298239e+00,  5.38846833e-01,\n",
       "         5.33221985e-01],\n",
       "       [ 1.49819126e+00,  1.98364292e+00,  1.97449858e+00,\n",
       "         1.47742838e+00,  7.52353658e-02,  2.68062692e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.83551906e-01, -9.46083599e-01,\n",
       "        -1.18284657e+00,  1.27298239e+00,  1.62198339e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -6.95474739e-01, -7.37470586e-01,\n",
       "        -5.43198168e-01, -1.12251166e+00, -1.08585801e+00,\n",
       "         5.33221985e-01],\n",
       "       [ 3.20935344e-01,  4.39233235e-02, -2.42014681e-01,\n",
       "        -1.62483326e-01, -1.12251166e+00, -1.62742629e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01,  3.70410780e-01,  2.01287970e-01,\n",
       "        -1.60118596e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.16333901e-01, -5.54934200e-01,\n",
       "        -1.05870031e+00,  7.52353658e-02,  2.68062692e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.09060370e+00,  6.70667248e-01,\n",
       "         6.30869959e-01, -1.12251166e+00, -1.62742629e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.25936473e-01, -1.36330962e+00,\n",
       "        -9.93671258e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "         5.33221985e-01],\n",
       "       [-8.56320571e-01, -9.16333901e-01, -3.72397814e-01,\n",
       "        -8.34054813e-01, -1.12251166e+00, -8.15073870e-01,\n",
       "         5.33221985e-01],\n",
       "       [-8.56320571e-01, -4.07397572e-01, -4.24551067e-01,\n",
       "        -2.72441212e-01,  7.52353658e-02,  2.68062692e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01,  6.20077658e-01,  4.09900983e-01,\n",
       "         5.19729448e-01,  7.52353658e-02,  5.38846833e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.98364292e+00,  1.63550243e+00,\n",
       "         2.28851688e+00, -1.12251166e+00, -8.15073870e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -5.13025867e-01, -4.76704321e-01,\n",
       "        -2.13323991e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -8.49115895e-01, -7.89623839e-01,\n",
       "        -1.17102292e+00,  1.27298239e+00,  1.62198339e+00,\n",
       "         5.33221985e-01],\n",
       "       [ 1.49819126e+00,  1.50351430e+00,  5.40284116e-01,\n",
       "         1.09907827e+00,  1.27298239e+00,  8.09630973e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -7.72295317e-01, -2.42014681e-01,\n",
       "        -8.18684325e-01, -1.12251166e+00, -1.08585801e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -1.03156477e+00, -1.02431348e+00,\n",
       "        -1.12491172e+00,  1.27298239e+00,  1.08041511e+00,\n",
       "         1.78158875e+00],\n",
       "       [ 1.49819126e+00,  1.98364292e+00,  3.27832991e+00,\n",
       "         1.54600452e+00, -1.12251166e+00, -8.15073870e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01, -3.68987283e-01,  7.09048374e-02,\n",
       "        -5.89309632e-01, -1.12251166e+00, -8.15073870e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.07139855e+00,  1.06181665e+00,\n",
       "         5.37464666e-01,  7.52353658e-02,  5.38846833e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.19623199e+00,  1.19219978e+00,\n",
       "         1.80612019e+00,  7.52353658e-02, -2.73505589e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.16333901e-01, -5.54934200e-01,\n",
       "        -8.88442834e-01, -1.12251166e+00, -5.44289730e-01,\n",
       "         5.33221985e-01],\n",
       "       [ 3.20935344e-01, -1.96140983e-01,  2.79517850e-01,\n",
       "        -3.19735041e-01,  1.27298239e+00,  8.09630973e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.25936473e-01, -1.15469661e+00,\n",
       "        -1.34364538e+00, -1.12251166e+00, -1.35664215e+00,\n",
       "         5.33221985e-01],\n",
       "       [-8.56320571e-01, -6.95474739e-01,  2.01287970e-01,\n",
       "        -4.42488839e-02, -1.12251166e+00, -1.08585801e+00,\n",
       "         5.33221985e-01],\n",
       "       [ 1.49819126e+00,  1.59954003e+00,  2.88718051e+00,\n",
       "         1.94445458e+00, -1.12251166e+00, -1.62742629e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -7.05077311e-01, -1.89861428e-01,\n",
       "        -5.49109734e-01, -1.12251166e+00, -1.08585801e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -7.05077311e-01, -4.24551067e-01,\n",
       "        -9.58201082e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -7.43487600e-01, -7.63547213e-01,\n",
       "        -8.56519493e-01, -1.12251166e+00, -5.44289730e-01,\n",
       "         5.33221985e-01],\n",
       "       [-8.56320571e-01, -6.95474739e-01,  2.79517850e-01,\n",
       "        -3.54023113e-01,  7.52353658e-02, -2.73505589e-01,\n",
       "         5.33221985e-01],\n",
       "       [-8.56320571e-01, -8.58718467e-01, -2.42014681e-01,\n",
       "        -7.03996979e-01, -1.12251166e+00, -1.62742629e+00,\n",
       "         5.33221985e-01],\n",
       "       [-8.56320571e-01, -9.93154479e-01, -8.67853719e-01,\n",
       "        -8.83713373e-01,  7.52353658e-02, -2.73505589e-01,\n",
       "         5.33221985e-01],\n",
       "       [-8.56320571e-01, -5.13025867e-01, -8.41777093e-01,\n",
       "        -6.64979706e-01, -1.12251166e+00, -1.35664215e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -1.03156477e+00, -1.02431348e+00,\n",
       "        -1.17693475e+00,  1.27298239e+00,  8.09630973e-01,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -8.29910751e-01, -8.41777093e-01,\n",
       "        -8.04496202e-01,  1.27298239e+00,  1.08041511e+00,\n",
       "         1.78158875e+00],\n",
       "       [ 1.49819126e+00,  1.98364292e+00,  2.23526484e+00,\n",
       "         1.71626199e+00, -1.12251166e+00, -1.08585801e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01, -1.96140983e-01,  1.49134717e-01,\n",
       "        -2.90176430e-01,  1.27298239e+00,  1.35119925e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.98364292e+00,  1.84411544e+00,\n",
       "         1.76592055e+00, -1.12251166e+00, -1.35664215e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.59954003e+00,  1.19219978e+00,\n",
       "         1.14637210e+00,  1.27298239e+00,  8.09630973e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -5.70641300e-01, -3.72397814e-01,\n",
       "        -3.06729283e-01,  1.27298239e+00,  1.08041511e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -5.13025867e-01, -3.72397814e-01,\n",
       "        -8.35237178e-01, -1.12251166e+00, -1.35664215e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01,  3.03192774e-01, -2.42014681e-01,\n",
       "         3.47107245e-01,  7.52353658e-02, -2.73505589e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.50351430e+00,  1.97449858e+00,\n",
       "         8.20045015e-01, -1.12251166e+00, -8.15073870e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.83551906e-01, -1.33723300e+00,\n",
       "        -1.38975685e+00,  7.52353658e-02, -2.73505589e-01,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -5.13025867e-01, -5.54934200e-01,\n",
       "        -3.91858019e-01,  7.52353658e-02, -2.73505589e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -7.05077311e-01, -4.50627694e-01,\n",
       "         1.01391368e-02, -1.12251166e+00, -1.08585801e+00,\n",
       "         5.33221985e-01],\n",
       "       [ 3.20935344e-01,  4.39233235e-02, -2.42014681e-01,\n",
       "        -7.85366950e-02, -1.12251166e+00, -8.15073870e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -7.72295317e-01, -2.42014681e-01,\n",
       "        -8.77801546e-01, -1.12251166e+00, -1.35664215e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -4.07397572e-01, -5.02780947e-01,\n",
       "        -1.36471551e-01,  1.27298239e+00,  5.38846833e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.16333901e-01, -1.02431348e+00,\n",
       "        -1.09417074e+00,  1.27298239e+00,  1.35119925e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.16333901e-01, -1.15469661e+00,\n",
       "        -9.53471621e-01,  7.52353658e-02, -2.72144865e-03,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.09060370e+00,  6.70667248e-01,\n",
       "         1.33318242e+00, -1.12251166e+00, -1.08585801e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -8.49115895e-01, -1.07646673e+00,\n",
       "        -8.93172034e-01,  1.27298239e+00,  1.35119925e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.06179598e+00,  1.19219978e+00,\n",
       "         1.52117511e+00, -1.12251166e+00, -5.44289730e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  2.26211751e+00,  2.44387786e+00,\n",
       "         1.62049223e+00, -1.12251166e+00, -1.62742629e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01,  6.20077658e-01,  1.49134717e-01,\n",
       "        -9.96081221e-03, -1.12251166e+00, -1.35664215e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01, -1.19320405e-01,  1.49134717e-01,\n",
       "        -3.00607613e-02,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  6.39282803e-01,  1.49134717e-01,\n",
       "         4.66524053e-01,  7.52353658e-02,  5.38846833e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01,  5.43257080e-01,  1.49134717e-01,\n",
       "         6.49787282e-01,  7.52353658e-02,  2.68062692e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -7.81897889e-01, -4.24551067e-01,\n",
       "        -4.32057657e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.93154479e-01, -8.93930346e-01,\n",
       "        -1.22186385e+00,  7.52353658e-02, -2.73505589e-01,\n",
       "         5.33221985e-01],\n",
       "       [ 1.49819126e+00,  1.07139855e+00,  6.70667248e-01,\n",
       "         1.02813765e+00,  1.27298239e+00,  8.09630973e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.06179598e+00,  1.19219978e+00,\n",
       "         5.46923328e-01, -1.12251166e+00, -1.62742629e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.25936473e-01, -4.24551067e-01,\n",
       "        -9.93671258e-01, -1.12251166e+00, -1.62742629e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -9.83551906e-01, -9.46083599e-01,\n",
       "        -1.11781753e+00,  1.27298239e+00,  1.62198339e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -9.83551906e-01, -1.15469661e+00,\n",
       "        -1.38384502e+00,  7.52353658e-02,  5.38846833e-01,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -7.53090173e-01, -2.42014681e-01,\n",
       "        -3.26829232e-01,  7.52353658e-02, -2.73505589e-01,\n",
       "         5.33221985e-01],\n",
       "       [ 1.49819126e+00,  1.98364292e+00,  1.84411544e+00,\n",
       "         1.67251526e+00, -1.12251166e+00, -1.08585801e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -1.10838535e+00, -1.36330962e+00,\n",
       "        -1.16511136e+00,  7.52353658e-02,  5.38846833e-01,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -9.16333901e-01, -1.02431348e+00,\n",
       "        -6.98085152e-01,  1.27298239e+00,  1.35119925e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -9.25936473e-01, -4.24551067e-01,\n",
       "        -8.17501960e-01, -1.12251166e+00, -8.15073870e-01,\n",
       "         1.78158875e+00],\n",
       "       [ 1.49819126e+00,  2.26211751e+00,  2.44387786e+00,\n",
       "         2.34290464e+00, -1.12251166e+00, -8.15073870e-01,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.98364292e+00,  2.23526484e+00,\n",
       "         1.60157465e+00,  7.52353658e-02,  2.68062692e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-1.44494853e+00, -1.18520592e+00, -1.11631549e-01,\n",
       "        -6.50791584e-01,  1.27298239e+00,  1.08041511e+00,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -7.43487600e-01, -7.63547213e-01,\n",
       "        -9.60565812e-01, -1.12251166e+00, -8.15073870e-01,\n",
       "         5.33221985e-01],\n",
       "       [-8.56320571e-01, -1.09878277e+00, -1.20684986e+00,\n",
       "        -1.35428641e+00,  7.52353658e-02,  2.68062692e-01,\n",
       "         5.33221985e-01],\n",
       "       [ 3.20935344e-01, -3.59384711e-01,  9.69814639e-02,\n",
       "        -4.77957191e-02,  7.52353658e-02, -2.72144865e-03,\n",
       "         1.78158875e+00],\n",
       "       [-8.56320571e-01, -8.49115895e-01, -1.07646673e+00,\n",
       "        -9.99583084e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -5.61038728e-01, -5.28857574e-01,\n",
       "        -5.26645315e-01,  1.27298239e+00,  1.62198339e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 3.20935344e-01,  3.60808208e-01,  2.79517850e-01,\n",
       "         3.24642566e-01,  1.27298239e+00,  8.09630973e-01,\n",
       "        -7.15144780e-01],\n",
       "       [-8.56320571e-01, -3.59384711e-01,  1.87515842e-02,\n",
       "        -2.01500598e-01,  1.27298239e+00,  1.08041511e+00,\n",
       "        -7.15144780e-01],\n",
       "       [ 1.49819126e+00,  1.19623199e+00,  1.19219978e+00,\n",
       "         1.30835327e+00, -1.12251166e+00, -1.08585801e+00,\n",
       "        -7.15144780e-01]])"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0000e+00 - mse: 0.0000e+00 - mae: 0.0000e+00 - cosine_similarity: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가해보기\n",
    "model.evaluate([[-8.56320571e-01, -7.05077311e-01, -6.59240707e-01, -4.08410873e-01,  1.27298239e+00,  1.62198339e+00, -7.15144780e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "예측값 [[3.0405784]\n",
      " [3.4374795]\n",
      " [2.584725 ]\n",
      " [2.8943982]\n",
      " [3.4657812]\n",
      " [2.8508492]\n",
      " [3.3452654]\n",
      " [4.0082517]\n",
      " [2.920998 ]\n",
      " [2.4647784]\n",
      " [3.388546 ]\n",
      " [3.5204973]\n",
      " [2.8936615]\n",
      " [3.1412563]\n",
      " [3.0231614]\n",
      " [3.8847508]\n",
      " [3.384447 ]\n",
      " [2.170804 ]\n",
      " [3.0230632]\n",
      " [3.507216 ]\n",
      " [2.6040125]\n",
      " [2.474597 ]\n",
      " [2.7289824]\n",
      " [2.7458634]\n",
      " [2.861258 ]\n",
      " [3.8068185]\n",
      " [2.607738 ]\n",
      " [2.6320558]\n",
      " [2.0142646]\n",
      " [3.846241 ]\n",
      " [3.32553  ]\n",
      " [3.628714 ]\n",
      " [2.6122293]\n",
      " [2.812131 ]\n",
      " [3.240182 ]\n",
      " [3.9824958]\n",
      " [2.3070421]\n",
      " [2.6717591]\n",
      " [3.0792503]\n",
      " [2.788897 ]\n",
      " [2.27847  ]\n",
      " [2.9796991]\n",
      " [2.4980412]\n",
      " [4.022116 ]\n",
      " [2.727643 ]\n",
      " [3.3017688]\n",
      " [2.9037566]\n",
      " [2.442142 ]\n",
      " [2.2698612]\n",
      " [2.5109506]\n",
      " [2.836248 ]\n",
      " [3.1438031]\n",
      " [3.016961 ]\n",
      " [3.7047539]\n",
      " [2.624105 ]\n",
      " [3.5919442]\n",
      " [2.5808196]\n",
      " [2.9658437]\n",
      " [2.665019 ]\n",
      " [2.1713147]\n",
      " [3.2368078]\n",
      " [2.9160643]\n",
      " [2.213644 ]\n",
      " [2.4082732]\n",
      " [2.473915 ]\n",
      " [2.7798605]\n",
      " [2.5959363]\n",
      " [3.6981616]\n",
      " [2.8854132]\n",
      " [3.2715077]\n",
      " [3.6768484]\n",
      " [3.5485487]\n",
      " [3.7165027]\n",
      " [2.5204206]\n",
      " [2.8029232]\n",
      " [2.6492534]\n",
      " [2.133191 ]\n",
      " [3.3417234]\n",
      " [2.6156206]\n",
      " [2.450729 ]\n",
      " [2.916099 ]\n",
      " [2.7147589]\n",
      " [3.473875 ]\n",
      " [3.260799 ]\n",
      " [2.2857018]\n",
      " [3.545724 ]\n",
      " [3.1814423]\n",
      " [3.5596304]\n",
      " [2.8519063]\n",
      " [3.971017 ]\n",
      " [3.0118308]\n",
      " [3.546218 ]\n",
      " [2.8593478]\n",
      " [3.008016 ]\n",
      " [2.2156296]\n",
      " [3.8201876]\n",
      " [3.4551086]\n",
      " [2.2404318]\n",
      " [2.9113965]\n",
      " [3.2692866]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"예측값 {model.predict(test_scal_data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('EV_PY39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1dde8d3f1fc6169eb2afb9c884f1482ff31994a855398e316a83a9dc8ff488b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
